{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "FEN Generator APS360 Summer 2021- Main Model using YOLOv5",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JoanneT8/FEN-Chess-Identifier-APS360-Summer-2021/blob/main/FEN_Generator_APS360_Summer_2021_Main_Model_using_YOLOv5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gIzdMhBJNb38"
      },
      "source": [
        "## Google Colab Shared Link\n",
        "Baseline Model Link: https://colab.research.google.com/drive/1hBLG7VLoNU6S6vvo8Ff9rpU0ix5F1Wwj?usp=sharing\n",
        "\n",
        "Main Model Link: https://colab.research.google.com/drive/1gLG2Td7MzgWcH2JUzr1E3Rst3kRTovYm?usp=sharing "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EYRQZVyvEZ40"
      },
      "source": [
        "# Creating the Main Model - Utilizing YOLOv5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O9Kuy44O90-Y"
      },
      "source": [
        "- Using Pre-trained model (YOLOv5x) from https://github.com/ultralytics/yolov5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fonNdl1Pcdhi",
        "outputId": "3a06d62e-e2de-41bb-bf95-ce57a6423cbe"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AV_IH-LWNghC"
      },
      "source": [
        "### Set-up"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rrS_5VnIHzpL",
        "outputId": "8fe5d95c-652d-4db2-a626-92a0a0dc96ee"
      },
      "source": [
        "# setting up dependencies needed to use YOLOv5\n",
        "!git clone https://github.com/ultralytics/yolov5"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'yolov5'...\n",
            "remote: Enumerating objects: 9310, done.\u001b[K\n",
            "remote: Counting objects: 100% (50/50), done.\u001b[K\n",
            "remote: Compressing objects: 100% (28/28), done.\u001b[K\n",
            "remote: Total 9310 (delta 26), reused 43 (delta 22), pack-reused 9260\u001b[K\n",
            "Receiving objects: 100% (9310/9310), 9.64 MiB | 22.80 MiB/s, done.\n",
            "Resolving deltas: 100% (6469/6469), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qWY9m4EjkxTS",
        "outputId": "18162d18-c42c-4344-91d4-0e2df1126f46"
      },
      "source": [
        "cd yolov5"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/yolov5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z1w5jrW8k1y6",
        "outputId": "ab54b7ed-9057-45fc-ce9e-e1fe28394b75"
      },
      "source": [
        "pip install -qr requirements.txt # installing dependencies needed for YOLOv5"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 3.0 MB 5.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 636 kB 40.8 MB/s \n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lVvdXY_agslo",
        "outputId": "3ad0f419-b23a-460b-c760-c024b1295c4d"
      },
      "source": [
        "!pip install wandb"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting wandb\n",
            "  Downloading wandb-0.11.2-py2.py3-none-any.whl (1.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.8 MB 7.3 MB/s \n",
            "\u001b[?25hCollecting GitPython>=1.0.0\n",
            "  Downloading GitPython-3.1.18-py3-none-any.whl (170 kB)\n",
            "\u001b[K     |████████████████████████████████| 170 kB 67.8 MB/s \n",
            "\u001b[?25hCollecting urllib3>=1.26.5\n",
            "  Downloading urllib3-1.26.6-py2.py3-none-any.whl (138 kB)\n",
            "\u001b[K     |████████████████████████████████| 138 kB 72.3 MB/s \n",
            "\u001b[?25hCollecting pathtools\n",
            "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
            "Requirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.15.0)\n",
            "Collecting configparser>=3.8.1\n",
            "  Downloading configparser-5.0.2-py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.23.0)\n",
            "Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.17.3)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from wandb) (5.4.1)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.4.8)\n",
            "Collecting subprocess32>=3.5.3\n",
            "  Downloading subprocess32-3.5.4.tar.gz (97 kB)\n",
            "\u001b[K     |████████████████████████████████| 97 kB 9.0 MB/s \n",
            "\u001b[?25hCollecting sentry-sdk>=1.0.0\n",
            "  Downloading sentry_sdk-1.3.1-py2.py3-none-any.whl (133 kB)\n",
            "\u001b[K     |████████████████████████████████| 133 kB 49.7 MB/s \n",
            "\u001b[?25hCollecting docker-pycreds>=0.4.0\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Collecting shortuuid>=0.5.0\n",
            "  Downloading shortuuid-1.0.1-py3-none-any.whl (7.5 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.8.1)\n",
            "Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.3)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (7.1.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.0 in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb) (3.7.4.3)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "  Downloading gitdb-4.0.7-py3-none-any.whl (63 kB)\n",
            "\u001b[K     |████████████████████████████████| 63 kB 1.9 MB/s \n",
            "\u001b[?25hCollecting smmap<5,>=3.0.1\n",
            "  Downloading smmap-4.0.0-py2.py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2021.5.30)\n",
            "Collecting requests<3,>=2.0.0\n",
            "  Downloading requests-2.26.0-py2.py3-none-any.whl (62 kB)\n",
            "\u001b[K     |████████████████████████████████| 62 kB 1.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2.0.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2.10)\n",
            "Building wheels for collected packages: subprocess32, pathtools\n",
            "  Building wheel for subprocess32 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for subprocess32: filename=subprocess32-3.5.4-py3-none-any.whl size=6502 sha256=2a40165a50e8ee3c468d574f29c6217d56666ef566c84f8213b0ddd9d82ac3db\n",
            "  Stored in directory: /root/.cache/pip/wheels/50/ca/fa/8fca8d246e64f19488d07567547ddec8eb084e8c0d7a59226a\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8806 sha256=c335ab8de1aaa58c6589cae07f9cfeef0f330c48fa258dcc730b367adfbc60e1\n",
            "  Stored in directory: /root/.cache/pip/wheels/3e/31/09/fa59cef12cdcfecc627b3d24273699f390e71828921b2cbba2\n",
            "Successfully built subprocess32 pathtools\n",
            "Installing collected packages: smmap, urllib3, gitdb, subprocess32, shortuuid, sentry-sdk, requests, pathtools, GitPython, docker-pycreds, configparser, wandb\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.26.0 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed GitPython-3.1.18 configparser-5.0.2 docker-pycreds-0.4.0 gitdb-4.0.7 pathtools-0.1.2 requests-2.26.0 sentry-sdk-1.3.1 shortuuid-1.0.1 smmap-4.0.0 subprocess32-3.5.4 urllib3-1.26.6 wandb-0.11.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TwSyggGmTrYz"
      },
      "source": [
        "# not sure what -qqq is, hopefully it's something related to saving models? I saw this on a website somewhere: https://wandb.ai/lavanyashukla/save_and_restore/reports/Saving-and-Restoring-Models-with-W-B--Vmlldzo3MDQ3Mw\n",
        "!pip install wandb -qq"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uTX9iDx63IK2",
        "outputId": "63240670-ea31-46f5-ee9b-99da93924433"
      },
      "source": [
        "''' \n",
        "Wandb (Weights and Biases) is a service that directly connects to the YOLOv5 model \n",
        "that will help track training curves, F1 score, and confusion matrices\n",
        "'''\n",
        "!wandb login --relogin"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter: \n",
            "Aborted!\n",
            "Error in atexit._run_exitfuncs:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.7/weakref.py\", line 623, in _exitfunc\n",
            "    @classmethod\n",
            "KeyboardInterrupt\n",
            "Exception ignored in: <finalize object at 0x7f0c5f993bb0; dead>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.7/weakref.py\", line 572, in __call__\n",
            "  File \"/usr/lib/python3.7/tempfile.py\", line 936, in _cleanup\n",
            "TypeError: 'NoneType' object is not callable\n",
            "Exception ignored in: <finalize object at 0x7f0c5f9935b0; dead>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.7/weakref.py\", line 572, in __call__\n",
            "  File \"/usr/lib/python3.7/tempfile.py\", line 936, in _cleanup\n",
            "TypeError: 'NoneType' object is not callable\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_eR4_etelKVV"
      },
      "source": [
        "import torch\n",
        "from IPython.display import Image, clear_output  # to display images"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lPz-TQHzlL2t",
        "outputId": "95a724cb-0c6b-497d-fa2e-9126a721607b"
      },
      "source": [
        "print(f\"Setup complete. Using torch {torch.__version__} ({torch.cuda.get_device_properties(0).name if torch.cuda.is_available() else 'CPU'})\")"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setup complete. Using torch 1.9.0+cu102 (Tesla K80)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B1jRBG6M_fZa"
      },
      "source": [
        "# split data into train, validation, and test sets in a 70:15:15 ratio (ratio can be changed but we'll stick with this for now)\n",
        "# annotated images: 120 (Kevin) + 45 (Morgan) + 68 (John) + 120 (Joanne) = 343 images\n",
        "# train = 240 \n",
        "# validation = 52 + 51\n",
        "\n",
        "# NOTE: Make sure the YOLO annotation files are in the same directory as the images themselves"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pWd8oKwkAZ9S",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c24a276c-0517-45aa-91c4-aa2d03ea3a9c"
      },
      "source": [
        "# Modify YAML file to specify path to train and validation folder, and info about number of classes and the names of those classes\n",
        "# hmm unsure of this part, the YAML file only specifies the number of classes (nc)\n",
        "\"\"\"\n",
        "example from:  https://michaelohanu.medium.com/yolov5-tutorial-75207a19a3aa \n",
        "\n",
        "train: /Users/macbook/Desktop/antenna/yolov5/data/train.txt\n",
        "val: /Users/macbook/Desktop/antenna/yolov5/data/val.txt\n",
        "\n",
        "# number of classes\n",
        "nc: 1\n",
        "# class names\n",
        "names: ['antenna'] \n",
        "\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\nexample from:  https://michaelohanu.medium.com/yolov5-tutorial-75207a19a3aa \\n\\ntrain: /Users/macbook/Desktop/antenna/yolov5/data/train.txt\\nval: /Users/macbook/Desktop/antenna/yolov5/data/val.txt\\n\\n# number of classes\\nnc: 1\\n# class names\\nnames: ['antenna'] \\n\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wtGV8GPjiy3t",
        "outputId": "5a69737d-d9d4-46e6-8cb9-57ed80eb822c"
      },
      "source": [
        "cd /content/yolov5"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/yolov5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4QzaAqG7XrYg",
        "outputId": "3e943842-565d-409c-fd09-f622f073a814"
      },
      "source": [
        "# downloading our .yaml file for our chess dataset -> it specifies the train and validation folder locations and the classes\n",
        "!gdown --id 1W9J7rGbrKBwyzYtSctip9irltiwQ8rYi"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1W9J7rGbrKBwyzYtSctip9irltiwQ8rYi\n",
            "To: /content/yolov5/FEN.yaml\n",
            "\r  0% 0.00/362 [00:00<?, ?B/s]\r100% 362/362 [00:00<00:00, 683kB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7yTNJAUgNdP2"
      },
      "source": [
        "## Training\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hy7Q8XeYvfb0"
      },
      "source": [
        "Combinations training log:\n",
        "b = Batch, e = epoch\n",
        "\n",
        "- yolov5x, b = 15, e = 100 (Aug 3, 12:05) Time taken: 53 min 55 sec \n",
        "    - validation loss is starting to level out (don't really need more epochs?), let's try changing the batch size next\n",
        "- yolov5x, b = 15, e = 100 (Aug 3, 12:05) Using ADAM OPTIMIZER Time taken:  ~ 1 hour\n",
        "- yolov5x, b = 30, e = 100 (Aug 3, to be done) Time taken: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OZcv93L0jrcm"
      },
      "source": [
        "# ok this didn't do what I thought it would do... i thought it would help save the model but i don't think so\n",
        "# wandb.init(project=\"YOLOv5\") - Joanne"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mWG6QbCi3kQA"
      },
      "source": [
        "WANDB_PROJECT = 'YOLOv5'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UBeuKqNaqxJz"
      },
      "source": [
        "import tensorflow as tf\n",
        "import datetime, os"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KKMu918vfMJp",
        "outputId": "7bad1887-f9c1-4305-de95-fad5707f583c"
      },
      "source": [
        "!python train.py --img 200 --batch 50 --epochs 200 \\\n",
        "  --data /content/yolov5/FEN.yaml --weights yolov5x.pt \\\n",
        "  --name yolov5x_b50_ep200_run_train282_val61_garbage --cache --project /content/drive/MyDrive/APS360_Project_Group_3/YOLOv5"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5x.pt, cfg=, data=/content/yolov5/FEN.yaml, hyp=data/hyps/hyp.scratch.yaml, epochs=200, batch_size=50, imgsz=200, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, evolve=None, bucket=, cache=ram, image_weights=False, device=, multi_scale=False, single_cls=False, adam=False, sync_bn=False, workers=8, project=/content/drive/MyDrive/APS360_Project_Group_3/YOLOv5, entity=None, name=yolov5x_b50_ep200_run_train282_val61_garbage, exist_ok=False, quad=False, linear_lr=False, label_smoothing=0.0, upload_dataset=False, bbox_interval=-1, save_period=-1, artifact_alias=latest, local_rank=-1, freeze=0\n",
            "\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 ✅\n",
            "YOLOv5 🚀 v5.0-358-g3e7c59a torch 1.9.0+cu102 CUDA:0 (Tesla T4, 15109.75MB)\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.2, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
            "\u001b[34m\u001b[1mWeights & Biases: \u001b[0mrun 'pip install wandb' to automatically track and visualize YOLOv5 🚀 runs (RECOMMENDED)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir /content/drive/MyDrive/APS360_Project_Group_3/YOLOv5', view at http://localhost:6006/\n",
            "2021-08-12 03:34:37.050981: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "Downloading https://github.com/ultralytics/yolov5/releases/download/v5.0/yolov5x.pt to yolov5x.pt...\n",
            "100% 168M/168M [00:00<00:00, 177MB/s]\n",
            "\n",
            "Overriding model.yaml nc=80 with nc=12\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      8800  models.common.Focus                     [3, 80, 3]                    \n",
            "  1                -1  1    115520  models.common.Conv                      [80, 160, 3, 2]               \n",
            "  2                -1  4    309120  models.common.C3                        [160, 160, 4]                 \n",
            "  3                -1  1    461440  models.common.Conv                      [160, 320, 3, 2]              \n",
            "  4                -1 12   3285760  models.common.C3                        [320, 320, 12]                \n",
            "  5                -1  1   1844480  models.common.Conv                      [320, 640, 3, 2]              \n",
            "  6                -1 12  13125120  models.common.C3                        [640, 640, 12]                \n",
            "  7                -1  1   7375360  models.common.Conv                      [640, 1280, 3, 2]             \n",
            "  8                -1  1   4099840  models.common.SPP                       [1280, 1280, [5, 9, 13]]      \n",
            "  9                -1  4  19676160  models.common.C3                        [1280, 1280, 4, False]        \n",
            " 10                -1  1    820480  models.common.Conv                      [1280, 640, 1, 1]             \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  4   5332480  models.common.C3                        [1280, 640, 4, False]         \n",
            " 14                -1  1    205440  models.common.Conv                      [640, 320, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  4   1335040  models.common.C3                        [640, 320, 4, False]          \n",
            " 18                -1  1    922240  models.common.Conv                      [320, 320, 3, 2]              \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  4   4922880  models.common.C3                        [640, 640, 4, False]          \n",
            " 21                -1  1   3687680  models.common.Conv                      [640, 640, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  4  19676160  models.common.C3                        [1280, 1280, 4, False]        \n",
            " 24      [17, 20, 23]  1    114393  models.yolo.Detect                      [12, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [320, 640, 1280]]\n",
            "Model Summary: 607 layers, 87318393 parameters, 87318393 gradients, 217.6 GFLOPs\n",
            "\n",
            "Transferred 788/794 items from yolov5x.pt\n",
            "Scaled weight_decay = 0.000390625\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD with parameter groups 131 weight, 134 weight (no decay), 134 bias\n",
            "WARNING: --img-size 200 must be multiple of max stride 32, updating to 224\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mversion 1.0.3 required by YOLOv5, but version 0.1.12 is currently installed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/content/drive/MyDrive/APS360_Project_Group_3/dataset/annotated/train_annotated.cache' images and labels... 282 found, 0 missing, 0 empty, 0 corrupted: 100% 282/282 [00:00<00:00, 2757094.94it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.0GB ram):  35% 98/282 [00:17<00:30,  6.11it/s]Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.7/multiprocessing/pool.py\", line 733, in next\n",
            "IndexError: pop from an empty deque\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"train.py\", line 600, in <module>\n",
            "    main(opt)\n",
            "  File \"train.py\", line 498, in main\n",
            "    train(opt.hyp, opt, device)\n",
            "  File \"train.py\", line 206, in train\n",
            "    prefix=colorstr('train: '))\n",
            "  File \"/content/yolov5/utils/datasets.py\", line 104, in create_dataloader\n",
            "    prefix=prefix)\n",
            "  File \"/content/yolov5/utils/datasets.py\", line 468, in __init__\n",
            "    for i, x in pbar:\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tqdm/std.py\", line 1104, in __iter__\n",
            "    for obj in iterable:\n",
            "  File \"/usr/lib/python3.7/multiprocessing/pool.py\", line 737, in next\n",
            "    self._cond.wait(timeout)\n",
            "  File \"/usr/lib/python3.7/threading.py\", line 296, in wait\n",
            "    waiter.acquire()\n",
            "KeyboardInterrupt\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.0GB ram):  35% 98/282 [00:17<00:32,  5.62it/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qVOK-MIQA5Fm",
        "outputId": "c954e1ee-9a0c-41d8-cf1c-5c49223b09fc"
      },
      "source": [
        "!python train.py --img 200 --batch 15 --epochs 100 \\\n",
        "  --data /content/yolov5/FEN.yaml --weights yolov5x.pt \\\n",
        "  --name yolov5x_b15_ep100_run_train282_val61_copy --cache --project /content/drive/MyDrive/APS360_Project_Group_3/YOLOv5"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://ultralytics.com/assets/Arial.ttf to /content/yolov5/Arial.ttf...\n",
            "100% 755k/755k [00:00<00:00, 18.5MB/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5x.pt, cfg=, data=/content/yolov5/FEN.yaml, hyp=data/hyps/hyp.scratch.yaml, epochs=100, batch_size=15, imgsz=200, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, evolve=None, bucket=, cache=ram, image_weights=False, device=, multi_scale=False, single_cls=False, adam=False, sync_bn=False, workers=8, project=/content/drive/MyDrive/APS360_Project_Group_3/YOLOv5, entity=None, name=yolov5x_b15_ep100_run_train282_val61_copy, exist_ok=False, quad=False, linear_lr=False, label_smoothing=0.0, upload_dataset=False, bbox_interval=-1, save_period=-1, artifact_alias=latest, local_rank=-1, freeze=0, patience=30\n",
            "\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 ✅\n",
            "YOLOv5 🚀 v5.0-405-gfad57c2 torch 1.9.0+cu102 CUDA:0 (Tesla K80, 11441.1875MB)\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.2, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
            "\u001b[34m\u001b[1mWeights & Biases: \u001b[0mrun 'pip install wandb' to automatically track and visualize YOLOv5 🚀 runs (RECOMMENDED)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir /content/drive/MyDrive/APS360_Project_Group_3/YOLOv5', view at http://localhost:6006/\n",
            "Downloading https://github.com/ultralytics/yolov5/releases/download/v5.0/yolov5x.pt to yolov5x.pt...\n",
            "100% 168M/168M [00:01<00:00, 123MB/s]\n",
            "\n",
            "Overriding model.yaml nc=80 with nc=12\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      8800  models.common.Focus                     [3, 80, 3]                    \n",
            "  1                -1  1    115520  models.common.Conv                      [80, 160, 3, 2]               \n",
            "  2                -1  4    309120  models.common.C3                        [160, 160, 4]                 \n",
            "  3                -1  1    461440  models.common.Conv                      [160, 320, 3, 2]              \n",
            "  4                -1 12   3285760  models.common.C3                        [320, 320, 12]                \n",
            "  5                -1  1   1844480  models.common.Conv                      [320, 640, 3, 2]              \n",
            "  6                -1 12  13125120  models.common.C3                        [640, 640, 12]                \n",
            "  7                -1  1   7375360  models.common.Conv                      [640, 1280, 3, 2]             \n",
            "  8                -1  1   4099840  models.common.SPP                       [1280, 1280, [5, 9, 13]]      \n",
            "  9                -1  4  19676160  models.common.C3                        [1280, 1280, 4, False]        \n",
            " 10                -1  1    820480  models.common.Conv                      [1280, 640, 1, 1]             \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  4   5332480  models.common.C3                        [1280, 640, 4, False]         \n",
            " 14                -1  1    205440  models.common.Conv                      [640, 320, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  4   1335040  models.common.C3                        [640, 320, 4, False]          \n",
            " 18                -1  1    922240  models.common.Conv                      [320, 320, 3, 2]              \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  4   4922880  models.common.C3                        [640, 640, 4, False]          \n",
            " 21                -1  1   3687680  models.common.Conv                      [640, 640, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  4  19676160  models.common.C3                        [1280, 1280, 4, False]        \n",
            " 24      [17, 20, 23]  1    114393  models.yolo.Detect                      [12, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [320, 640, 1280]]\n",
            "Model Summary: 607 layers, 87318393 parameters, 87318393 gradients, 217.6 GFLOPs\n",
            "\n",
            "Transferred 788/794 items from yolov5x.pt\n",
            "Scaled weight_decay = 0.00046875\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD with parameter groups 131 weight, 134 weight (no decay), 134 bias\n",
            "WARNING: --img-size 200 must be multiple of max stride 32, updating to 224\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mversion 1.0.3 required by YOLOv5, but version 0.1.12 is currently installed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/content/drive/MyDrive/APS360_Project_Group_3/dataset/annotated/train_annotated.cache' images and labels... 282 found, 0 missing, 0 empty, 0 corrupted: 100% 282/282 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.0GB ram): 100% 282/282 [00:39<00:00,  7.11it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning '/content/drive/MyDrive/APS360_Project_Group_3/dataset/annotated/val_annotated.cache' images and labels... 61 found, 0 missing, 0 empty, 0 corrupted: 100% 61/61 [00:00<?, ?it/s]\n",
            "  0% 0/61 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.0GB ram):   2% 1/61 [00:00<00:14,  4.15it/s]\u001b[A\n",
            "\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.0GB ram):   5% 3/61 [00:00<00:07,  7.75it/s]\u001b[A\n",
            "\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.0GB ram):   8% 5/61 [00:00<00:06,  8.97it/s]\u001b[A\n",
            "\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.0GB ram):  11% 7/61 [00:00<00:05,  9.76it/s]\u001b[A\n",
            "\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.0GB ram):  15% 9/61 [00:00<00:05, 10.23it/s]\u001b[A\n",
            "\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.0GB ram):  18% 11/61 [00:01<00:05,  9.82it/s]\u001b[A\n",
            "\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.0GB ram):  21% 13/61 [00:01<00:05,  9.14it/s]\u001b[A\n",
            "\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.0GB ram):  25% 15/61 [00:01<00:04,  9.22it/s]\u001b[A\n",
            "\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.0GB ram):  28% 17/61 [00:01<00:04,  9.43it/s]\u001b[A\n",
            "\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.0GB ram):  31% 19/61 [00:02<00:04,  8.68it/s]\u001b[A\n",
            "\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.0GB ram):  34% 21/61 [00:02<00:04,  9.77it/s]\u001b[A\n",
            "\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.0GB ram):  38% 23/61 [00:02<00:03,  9.52it/s]\u001b[A\n",
            "\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.0GB ram):  41% 25/61 [00:02<00:04,  8.98it/s]\u001b[A\n",
            "\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.0GB ram):  44% 27/61 [00:02<00:03,  9.61it/s]\u001b[A\n",
            "\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.0GB ram):  48% 29/61 [00:03<00:03,  8.58it/s]\u001b[A\n",
            "\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.0GB ram):  51% 31/61 [00:03<00:03,  8.45it/s]\u001b[A\n",
            "\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.0GB ram):  54% 33/61 [00:03<00:03,  8.76it/s]\u001b[A\n",
            "\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.0GB ram):  57% 35/61 [00:03<00:02,  8.83it/s]\u001b[A\n",
            "\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.0GB ram):  61% 37/61 [00:05<00:07,  3.25it/s]\u001b[A\n",
            "\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.0GB ram):  64% 39/61 [00:05<00:05,  3.97it/s]\u001b[A\n",
            "\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.0GB ram):  67% 41/61 [00:05<00:03,  5.03it/s]\u001b[A\n",
            "\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.0GB ram):  70% 43/61 [00:06<00:03,  5.80it/s]\u001b[A\n",
            "\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.0GB ram):  74% 45/61 [00:06<00:02,  6.68it/s]\u001b[A\n",
            "\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.0GB ram):  77% 47/61 [00:06<00:01,  7.05it/s]\u001b[A\n",
            "\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.0GB ram):  80% 49/61 [00:06<00:01,  7.40it/s]\u001b[A\n",
            "\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.0GB ram):  84% 51/61 [00:06<00:01,  8.81it/s]\u001b[A\n",
            "\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.0GB ram):  87% 53/61 [00:07<00:00,  9.43it/s]\u001b[A\n",
            "\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.0GB ram):  90% 55/61 [00:07<00:00,  9.37it/s]\u001b[A\n",
            "\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.0GB ram):  93% 57/61 [00:07<00:00,  9.80it/s]\u001b[A\n",
            "\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.0GB ram):  97% 59/61 [00:07<00:00, 10.25it/s]\u001b[A\n",
            "\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.0GB ram): 100% 61/61 [00:07<00:00,  7.81it/s]\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "Plotting labels... \n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning '/content/drive/MyDrive/APS360_Project_Group_3/dataset/annotated/val_annotated.cache' images and labels... 61 found, 0 missing, 0 empty, 0 corrupted: 100% 61/61 [00:07<?, ?it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning '/content/drive/MyDrive/APS360_Project_Group_3/dataset/annotated/val_annotated.cache' images and labels... 61 found, 0 missing, 0 empty, 0 corrupted: 100% 61/61 [00:07<?, ?it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning '/content/drive/MyDrive/APS360_Project_Group_3/dataset/annotated/val_annotated.cache' images and labels... 61 found, 0 missing, 0 empty, 0 corrupted: 100% 61/61 [00:07<?, ?it/s]\n",
            "\n",
            "\u001b[34m\u001b[1mautoanchor: \u001b[0mAnalyzing anchors... anchors/target = 5.03, Best Possible Recall (BPR) = 0.9994\n",
            "Image sizes 224 train, 224 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1m/content/drive/MyDrive/APS360_Project_Group_3/YOLOv5/yolov5x_b15_ep100_run_train282_val61_copy\u001b[0m\n",
            "Starting training for 100 epochs...\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "      0/99     3.14G    0.1278   0.05572   0.06812       204       224: 100% 19/19 [00:36<00:00,  1.90s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 3/3 [00:02<00:00,  1.41it/s]\n",
            "                 all         61        658    0.00022    0.00717   0.000116   1.95e-05\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "      1/99      3.3G      0.12   0.06235   0.06764       174       224: 100% 19/19 [00:27<00:00,  1.42s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 3/3 [00:02<00:00,  1.39it/s]\n",
            "                 all         61        658     0.0855    0.00198   0.000575   0.000139\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "      2/99      3.3G    0.1139   0.05941   0.06734       135       224: 100% 19/19 [00:25<00:00,  1.36s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 3/3 [00:02<00:00,  1.35it/s]\n",
            "                 all         61        658     0.0149      0.227     0.0166    0.00361\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "      3/99      3.3G    0.1075   0.05403   0.06669       203       224: 100% 19/19 [00:25<00:00,  1.36s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 3/3 [00:02<00:00,  1.20it/s]\n",
            "                 all         61        658      0.044      0.239      0.043     0.0116\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "      4/99      3.3G   0.08995    0.0497   0.06596       163       224: 100% 19/19 [00:25<00:00,  1.36s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 3/3 [00:02<00:00,  1.06it/s]\n",
            "                 all         61        658      0.157      0.367     0.0666     0.0216\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "      5/99      3.3G   0.07445   0.04475   0.06497       184       224: 100% 19/19 [00:25<00:00,  1.36s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 3/3 [00:02<00:00,  1.21it/s]\n",
            "                 all         61        658       0.18      0.506      0.125     0.0433\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "      6/99      3.3G   0.06223   0.04123   0.06465       198       224: 100% 19/19 [00:25<00:00,  1.36s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 3/3 [00:02<00:00,  1.22it/s]\n",
            "                 all         61        658      0.213      0.464      0.156       0.07\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "      7/99      3.3G   0.05708   0.04069   0.06368       214       224: 100% 19/19 [00:25<00:00,  1.35s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 3/3 [00:02<00:00,  1.28it/s]\n",
            "                 all         61        658      0.206      0.507      0.186     0.0903\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "      8/99      3.3G   0.07084   0.03988   0.06319       182       224: 100% 19/19 [00:25<00:00,  1.34s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 3/3 [00:02<00:00,  1.31it/s]\n",
            "                 all         61        658       0.12      0.632      0.192     0.0843\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "      9/99      3.3G   0.06495   0.03925    0.0632       163       224: 100% 19/19 [00:25<00:00,  1.32s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 3/3 [00:02<00:00,  1.30it/s]\n",
            "                 all         61        658     0.0992      0.389      0.148     0.0733\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     10/99      3.3G   0.06595   0.03693   0.06256       177       224: 100% 19/19 [00:25<00:00,  1.32s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 3/3 [00:02<00:00,  1.32it/s]\n",
            "                 all         61        658      0.221      0.307      0.192     0.0955\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     11/99      3.3G   0.06269   0.03932   0.06234       174       224: 100% 19/19 [00:25<00:00,  1.32s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 3/3 [00:02<00:00,  1.33it/s]\n",
            "                 all         61        658      0.169      0.506      0.241      0.117\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     12/99      3.3G   0.06338   0.03834   0.06156       196       224: 100% 19/19 [00:25<00:00,  1.35s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 3/3 [00:02<00:00,  1.32it/s]\n",
            "                 all         61        658      0.297      0.323      0.211     0.0638\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     13/99      3.3G   0.06094   0.03729   0.06162       168       224: 100% 19/19 [00:25<00:00,  1.32s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 3/3 [00:02<00:00,  1.33it/s]\n",
            "                 all         61        658      0.495      0.365      0.359      0.192\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     14/99      3.3G   0.06056   0.03882    0.0607       196       224: 100% 19/19 [00:25<00:00,  1.32s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 3/3 [00:02<00:00,  1.32it/s]\n",
            "                 all         61        658      0.482      0.372      0.298      0.121\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     15/99      3.3G   0.05725   0.03701    0.0597       179       224: 100% 19/19 [00:25<00:00,  1.32s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 3/3 [00:02<00:00,  1.34it/s]\n",
            "                 all         61        658      0.329      0.501      0.405      0.182\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     16/99      3.3G   0.05898   0.03707   0.05884       171       224: 100% 19/19 [00:25<00:00,  1.33s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 3/3 [00:02<00:00,  1.28it/s]\n",
            "                 all         61        658      0.403       0.49      0.365      0.163\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     17/99      3.3G   0.05413   0.03519   0.05772       212       224: 100% 19/19 [00:25<00:00,  1.32s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 3/3 [00:02<00:00,  1.35it/s]\n",
            "                 all         61        658       0.25      0.817      0.493      0.246\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     18/99      3.3G   0.05441   0.03647   0.05663       155       224: 100% 19/19 [00:25<00:00,  1.32s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 3/3 [00:02<00:00,  1.34it/s]\n",
            "                 all         61        658      0.286      0.842      0.523      0.265\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     19/99      3.3G   0.05323     0.036   0.05483       168       224: 100% 19/19 [00:25<00:00,  1.33s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 3/3 [00:02<00:00,  1.34it/s]\n",
            "                 all         61        658      0.411      0.799      0.621      0.345\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     20/99      3.3G   0.05254   0.03578    0.0543       129       224: 100% 19/19 [00:25<00:00,  1.34s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 3/3 [00:02<00:00,  1.34it/s]\n",
            "                 all         61        658      0.343       0.82      0.591      0.296\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     21/99      3.3G   0.05142   0.03571   0.05289       153       224: 100% 19/19 [00:25<00:00,  1.32s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 3/3 [00:02<00:00,  1.35it/s]\n",
            "                 all         61        658      0.485      0.791      0.702      0.373\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     22/99      3.3G   0.05094   0.03535   0.05143       143       224: 100% 19/19 [00:25<00:00,  1.32s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 3/3 [00:02<00:00,  1.35it/s]\n",
            "                 all         61        658      0.529      0.737      0.722      0.381\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     23/99      3.3G   0.04957   0.03328   0.04986       223       224: 100% 19/19 [00:25<00:00,  1.32s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 3/3 [00:02<00:00,  1.36it/s]\n",
            "                 all         61        658      0.517      0.729      0.692      0.341\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     24/99      3.3G   0.05606   0.03606   0.04798       177       224: 100% 19/19 [00:25<00:00,  1.32s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 3/3 [00:02<00:00,  1.35it/s]\n",
            "                 all         61        658      0.531      0.814      0.799      0.465\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     25/99      3.3G    0.0563   0.03549   0.04687       161       224: 100% 19/19 [00:24<00:00,  1.30s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 3/3 [00:02<00:00,  1.35it/s]\n",
            "                 all         61        658      0.491      0.847      0.792      0.437\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     26/99      3.3G    0.0522   0.03321   0.04539       190       224: 100% 19/19 [00:24<00:00,  1.31s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 3/3 [00:02<00:00,  1.35it/s]\n",
            "                 all         61        658      0.444       0.79      0.729      0.346\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     27/99      3.3G   0.05584   0.03376   0.04399       186       224: 100% 19/19 [00:24<00:00,  1.31s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 3/3 [00:02<00:00,  1.36it/s]\n",
            "                 all         61        658      0.428      0.767      0.705      0.358\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     28/99      3.3G    0.0555   0.03583   0.04218       192       224: 100% 19/19 [00:25<00:00,  1.32s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 3/3 [00:02<00:00,  1.35it/s]\n",
            "                 all         61        658       0.49      0.834      0.807      0.431\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     29/99      3.3G   0.05138   0.03395   0.04008       165       224: 100% 19/19 [00:24<00:00,  1.30s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 3/3 [00:02<00:00,  1.35it/s]\n",
            "                 all         61        658      0.467      0.893      0.824      0.452\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     30/99      3.3G   0.05436   0.03626   0.03977       189       224: 100% 19/19 [00:24<00:00,  1.31s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 3/3 [00:02<00:00,  1.37it/s]\n",
            "                 all         61        658      0.634      0.848      0.877      0.534\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     31/99      3.3G   0.05123   0.03311   0.03611       161       224: 100% 19/19 [00:24<00:00,  1.30s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 3/3 [00:02<00:00,  1.36it/s]\n",
            "                 all         61        658      0.542       0.88      0.802      0.423\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     32/99      3.3G   0.05056   0.03456   0.03426       172       224: 100% 19/19 [00:24<00:00,  1.32s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 3/3 [00:02<00:00,  1.25it/s]\n",
            "                 all         61        658      0.585      0.938      0.886      0.525\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     33/99      3.3G   0.05115   0.03402   0.03316       181       224: 100% 19/19 [00:24<00:00,  1.31s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 3/3 [00:02<00:00,  1.36it/s]\n",
            "                 all         61        658      0.467      0.939      0.833      0.469\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     34/99      3.3G   0.05136   0.03447   0.03067       173       224: 100% 19/19 [00:24<00:00,  1.30s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 3/3 [00:02<00:00,  1.36it/s]\n",
            "                 all         61        658       0.64      0.941      0.882      0.503\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     35/99      3.3G    0.0504   0.03446   0.02914       173       224: 100% 19/19 [00:24<00:00,  1.30s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 3/3 [00:02<00:00,  1.36it/s]\n",
            "                 all         61        658      0.772      0.973      0.913      0.537\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     36/99      3.3G   0.04929   0.03392   0.02775       205       224: 100% 19/19 [00:25<00:00,  1.32s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 3/3 [00:02<00:00,  1.29it/s]\n",
            "                 all         61        658      0.809      0.941      0.934      0.526\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     37/99      3.3G   0.04855   0.03259   0.02593       140       224: 100% 19/19 [00:24<00:00,  1.30s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 3/3 [00:02<00:00,  1.37it/s]\n",
            "                 all         61        658       0.83      0.932      0.925       0.49\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     38/99      3.3G   0.04775   0.03327   0.02487       127       224: 100% 19/19 [00:24<00:00,  1.31s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 3/3 [00:02<00:00,  1.34it/s]\n",
            "                 all         61        658      0.874      0.961      0.953      0.599\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     39/99      3.3G   0.04777   0.03265   0.02284       211       224: 100% 19/19 [00:24<00:00,  1.31s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 3/3 [00:02<00:00,  1.36it/s]\n",
            "                 all         61        658      0.888      0.939       0.95      0.581\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     40/99      3.3G   0.05123   0.03307   0.02091       175       224: 100% 19/19 [00:24<00:00,  1.30s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 3/3 [00:02<00:00,  1.33it/s]\n",
            "                 all         61        658      0.729       0.93      0.949      0.529\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     41/99      3.3G   0.04831   0.03285   0.02137       190       224: 100% 19/19 [00:24<00:00,  1.30s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 3/3 [00:02<00:00,  1.37it/s]\n",
            "                 all         61        658      0.782       0.94      0.946      0.558\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     42/99      3.3G   0.05001   0.03366   0.02056       178       224: 100% 19/19 [00:24<00:00,  1.30s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 3/3 [00:02<00:00,  1.35it/s]\n",
            "                 all         61        658      0.935      0.958      0.973      0.595\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     43/99      3.3G   0.04794   0.03317    0.0201       171       224: 100% 19/19 [00:24<00:00,  1.30s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 3/3 [00:02<00:00,  1.37it/s]\n",
            "                 all         61        658       0.93      0.956      0.975      0.634\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     44/99      3.3G   0.04908   0.03402   0.01948       198       224: 100% 19/19 [00:24<00:00,  1.30s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 3/3 [00:02<00:00,  1.37it/s]\n",
            "                 all         61        658      0.859       0.95      0.951      0.506\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     45/99      3.3G   0.04892   0.03313   0.01778       170       224: 100% 19/19 [00:24<00:00,  1.31s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 3/3 [00:02<00:00,  1.37it/s]\n",
            "                 all         61        658      0.952      0.972      0.985      0.587\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     46/99      3.3G   0.04903   0.03342   0.01805       220       224: 100% 19/19 [00:24<00:00,  1.30s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 3/3 [00:02<00:00,  1.35it/s]\n",
            "                 all         61        658      0.958      0.971      0.983      0.617\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     47/99      3.3G   0.04546   0.03222   0.01718       187       224: 100% 19/19 [00:24<00:00,  1.30s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 3/3 [00:02<00:00,  1.37it/s]\n",
            "                 all         61        658      0.956      0.976      0.982      0.582\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     48/99      3.3G   0.04321   0.03143   0.01742       190       224: 100% 19/19 [00:24<00:00,  1.30s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 3/3 [00:02<00:00,  1.37it/s]\n",
            "                 all         61        658      0.941       0.98      0.984      0.619\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     49/99      3.3G   0.04252   0.03191   0.01621       155       224: 100% 19/19 [00:24<00:00,  1.31s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 3/3 [00:02<00:00,  1.36it/s]\n",
            "                 all         61        658      0.958      0.947      0.971      0.615\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     50/99      3.3G   0.04483   0.03321   0.01585       192       224: 100% 19/19 [00:24<00:00,  1.30s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 3/3 [00:02<00:00,  1.36it/s]\n",
            "                 all         61        658      0.908      0.966      0.981        0.6\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     51/99      3.3G   0.04595    0.0332   0.01515       186       224: 100% 19/19 [00:24<00:00,  1.30s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 3/3 [00:02<00:00,  1.36it/s]\n",
            "                 all         61        658      0.966      0.952      0.985      0.585\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     52/99      3.3G   0.04444   0.03193   0.01473       183       224: 100% 19/19 [00:24<00:00,  1.30s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 3/3 [00:02<00:00,  1.36it/s]\n",
            "                 all         61        658      0.979      0.962      0.984      0.597\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     53/99      3.3G   0.04066   0.03041   0.01497       165       224: 100% 19/19 [00:24<00:00,  1.30s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 3/3 [00:02<00:00,  1.24it/s]\n",
            "                 all         61        658      0.974      0.987      0.986      0.638\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     54/99      3.3G   0.04104   0.03054   0.01418       182       224: 100% 19/19 [00:24<00:00,  1.30s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 3/3 [00:02<00:00,  1.36it/s]\n",
            "                 all         61        658      0.958      0.982      0.978      0.638\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     55/99      3.3G   0.04156    0.0317   0.01371       211       224: 100% 19/19 [00:24<00:00,  1.30s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 3/3 [00:02<00:00,  1.36it/s]\n",
            "                 all         61        658      0.963      0.985      0.984      0.631\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     56/99      3.3G   0.04016   0.02981   0.01364       148       224: 100% 19/19 [00:24<00:00,  1.30s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 3/3 [00:02<00:00,  1.36it/s]\n",
            "                 all         61        658      0.966      0.975      0.981      0.622\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     57/99      3.3G   0.03922   0.02921   0.01276       195       224: 100% 19/19 [00:24<00:00,  1.30s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 3/3 [00:02<00:00,  1.28it/s]\n",
            "                 all         61        658      0.975      0.972      0.978      0.562\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     58/99      3.3G   0.04041   0.03226   0.01334       202       224: 100% 19/19 [00:24<00:00,  1.30s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 3/3 [00:02<00:00,  1.37it/s]\n",
            "                 all         61        658      0.957      0.956      0.962       0.54\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     59/99      3.3G   0.04069   0.03018    0.0131       151       224: 100% 19/19 [00:24<00:00,  1.30s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 3/3 [00:02<00:00,  1.36it/s]\n",
            "                 all         61        658      0.972      0.982      0.985      0.636\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     60/99      3.3G   0.03622   0.02933   0.01258       176       224: 100% 19/19 [00:24<00:00,  1.31s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 3/3 [00:02<00:00,  1.37it/s]\n",
            "                 all         61        658      0.982      0.979      0.983      0.607\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     61/99      3.3G   0.03733   0.02936   0.01174       192       224: 100% 19/19 [00:24<00:00,  1.30s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 3/3 [00:02<00:00,  1.37it/s]\n",
            "                 all         61        658      0.982      0.985      0.983      0.649\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     62/99      3.3G   0.03717   0.02833   0.01147       163       224: 100% 19/19 [00:25<00:00,  1.32s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 3/3 [00:02<00:00,  1.37it/s]\n",
            "                 all         61        658       0.98      0.989      0.984      0.647\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     63/99      3.3G   0.03556   0.02797   0.01136       165       224: 100% 19/19 [00:24<00:00,  1.30s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 3/3 [00:02<00:00,  1.36it/s]\n",
            "                 all         61        658      0.979      0.989      0.983      0.637\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     64/99      3.3G   0.03464   0.02816   0.01072       206       224: 100% 19/19 [00:24<00:00,  1.30s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 3/3 [00:02<00:00,  1.36it/s]\n",
            "                 all         61        658      0.984      0.988      0.983      0.641\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     65/99      3.3G   0.03611   0.02719   0.01083       172       224: 100% 19/19 [00:24<00:00,  1.30s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 3/3 [00:02<00:00,  1.36it/s]\n",
            "                 all         61        658      0.984      0.988      0.985      0.645\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     66/99      3.3G   0.03649    0.0282   0.01209       143       224: 100% 19/19 [00:24<00:00,  1.30s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 3/3 [00:02<00:00,  1.31it/s]\n",
            "                 all         61        658      0.978      0.982      0.987      0.643\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     67/99      3.3G   0.03469   0.02762   0.01164       133       224: 100% 19/19 [00:24<00:00,  1.30s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 3/3 [00:02<00:00,  1.38it/s]\n",
            "                 all         61        658      0.977      0.989      0.989      0.646\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     68/99      3.3G   0.03386   0.02774   0.01035       238       224: 100% 19/19 [00:24<00:00,  1.30s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 3/3 [00:02<00:00,  1.36it/s]\n",
            "                 all         61        658      0.974      0.989      0.987      0.645\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     69/99      3.3G    0.0319   0.02744  0.009478       194       224: 100% 19/19 [00:24<00:00,  1.30s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 3/3 [00:02<00:00,  1.38it/s]\n",
            "                 all         61        658      0.969      0.975       0.98      0.588\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     70/99      3.3G   0.03399   0.02807   0.00992       161       224: 100% 19/19 [00:24<00:00,  1.29s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 3/3 [00:02<00:00,  1.37it/s]\n",
            "                 all         61        658      0.966      0.978      0.978      0.587\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     71/99      3.3G   0.03547   0.02925   0.00974       172       224: 100% 19/19 [00:24<00:00,  1.30s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 3/3 [00:02<00:00,  1.37it/s]\n",
            "                 all         61        658      0.974      0.985      0.987      0.604\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     72/99      3.3G   0.03284   0.02708    0.0102       201       224: 100% 19/19 [00:24<00:00,  1.30s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 3/3 [00:02<00:00,  1.34it/s]\n",
            "                 all         61        658      0.974      0.987      0.988       0.63\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     73/99      3.3G   0.03273   0.02736   0.01051       186       224: 100% 19/19 [00:24<00:00,  1.30s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 3/3 [00:02<00:00,  1.36it/s]\n",
            "                 all         61        658      0.977      0.983      0.988      0.605\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     74/99      3.3G   0.03318   0.02889  0.008811       222       224: 100% 19/19 [00:24<00:00,  1.30s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 3/3 [00:02<00:00,  1.37it/s]\n",
            "                 all         61        658      0.979      0.982      0.986      0.597\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     75/99      3.3G   0.03216    0.0271  0.009347       164       224: 100% 19/19 [00:24<00:00,  1.31s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 3/3 [00:02<00:00,  1.37it/s]\n",
            "                 all         61        658      0.979      0.984      0.987      0.631\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     76/99      3.3G   0.03204   0.02694  0.009226       196       224: 100% 19/19 [00:24<00:00,  1.30s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 3/3 [00:02<00:00,  1.37it/s]\n",
            "                 all         61        658      0.978      0.983      0.986       0.61\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     77/99      3.3G    0.0314   0.02647      0.01       224       224: 100% 19/19 [00:24<00:00,  1.30s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 3/3 [00:02<00:00,  1.37it/s]\n",
            "                 all         61        658      0.979      0.982       0.99       0.64\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     78/99      3.3G   0.03307   0.02666  0.009496       178       224: 100% 19/19 [00:24<00:00,  1.30s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 3/3 [00:02<00:00,  1.38it/s]\n",
            "                 all         61        658      0.973      0.981      0.989      0.626\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     79/99      3.3G   0.03146   0.02669  0.009314       152       224: 100% 19/19 [00:24<00:00,  1.31s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 3/3 [00:02<00:00,  1.38it/s]\n",
            "                 all         61        658       0.98      0.981       0.99       0.63\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     80/99      3.3G   0.03038   0.02662  0.009413       166       224: 100% 19/19 [00:24<00:00,  1.30s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 3/3 [00:02<00:00,  1.38it/s]\n",
            "                 all         61        658      0.978      0.982      0.989      0.623\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     81/99      3.3G   0.02901   0.02699  0.008873       174       224: 100% 19/19 [00:24<00:00,  1.30s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 3/3 [00:02<00:00,  1.37it/s]\n",
            "                 all         61        658      0.973       0.98      0.986      0.636\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     82/99      3.3G   0.02951   0.02588  0.008542       172       224: 100% 19/19 [00:24<00:00,  1.29s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 3/3 [00:02<00:00,  1.37it/s]\n",
            "                 all         61        658      0.974      0.977      0.985      0.613\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     83/99      3.3G   0.03067   0.02665  0.009203       210       224: 100% 19/19 [00:24<00:00,  1.31s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 3/3 [00:02<00:00,  1.35it/s]\n",
            "                 all         61        658      0.974      0.985      0.984      0.621\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     84/99      3.3G   0.03014   0.02645  0.009146       189       224: 100% 19/19 [00:24<00:00,  1.30s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 3/3 [00:02<00:00,  1.38it/s]\n",
            "                 all         61        658      0.978      0.983      0.984      0.613\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     85/99      3.3G   0.02792   0.02479  0.008161       264       224: 100% 19/19 [00:24<00:00,  1.30s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 3/3 [00:02<00:00,  1.37it/s]\n",
            "                 all         61        658      0.978      0.981      0.987      0.641\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     86/99      3.3G   0.02968   0.02609  0.008908       135       224: 100% 19/19 [00:24<00:00,  1.30s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 3/3 [00:02<00:00,  1.38it/s]\n",
            "                 all         61        658      0.981      0.982      0.985       0.62\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     87/99      3.3G   0.03015   0.02632  0.008119       180       224: 100% 19/19 [00:24<00:00,  1.31s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 3/3 [00:02<00:00,  1.34it/s]\n",
            "                 all         61        658       0.98      0.982      0.983      0.613\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     88/99      3.3G   0.03244    0.0262  0.008333       144       224: 100% 19/19 [00:24<00:00,  1.30s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 3/3 [00:02<00:00,  1.37it/s]\n",
            "                 all         61        658      0.982      0.986      0.988      0.619\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     89/99      3.3G    0.0297   0.02528  0.007945       228       224: 100% 19/19 [00:24<00:00,  1.30s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 3/3 [00:02<00:00,  1.37it/s]\n",
            "                 all         61        658      0.974      0.989      0.989      0.629\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     90/99      3.3G   0.02998   0.02579  0.008955       152       224: 100% 19/19 [00:24<00:00,  1.30s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 3/3 [00:02<00:00,  1.38it/s]\n",
            "                 all         61        658      0.977      0.984      0.988      0.612\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     91/99      3.3G   0.03086   0.02683  0.008696       165       224: 100% 19/19 [00:24<00:00,  1.30s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 3/3 [00:02<00:00,  1.26it/s]\n",
            "                 all         61        658      0.977      0.983      0.986        0.6\n",
            "EarlyStopping patience 30 exceeded, stopping training.\n",
            "\n",
            "92 epochs completed in 0.842 hours.\n",
            "Optimizer stripped from /content/drive/MyDrive/APS360_Project_Group_3/YOLOv5/yolov5x_b15_ep100_run_train282_val61_copy/weights/last.pt, 175.2MB\n",
            "Optimizer stripped from /content/drive/MyDrive/APS360_Project_Group_3/YOLOv5/yolov5x_b15_ep100_run_train282_val61_copy/weights/best.pt, 175.2MB\n",
            "Results saved to \u001b[1m/content/drive/MyDrive/APS360_Project_Group_3/YOLOv5/yolov5x_b15_ep100_run_train282_val61_copy\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dHioLzVA7MI7"
      },
      "source": [
        "## Final Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jDkogcuC7RoR"
      },
      "source": [
        "Fine Tuned Hyperparameters: \n",
        "- SGD optimizer (Adam optimizer resulted in very jaggy/inconsistent/unpredictable training curves)\n",
        "- Batch size = 15\n",
        "- Epoch = 100\n",
        "- YOLOv5 model adjusts learning rate as the model trains\n",
        "\n",
        "Dataset:\n",
        "- 282 train images\n",
        "- 61 validation images\n",
        "- 61 test images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9dYm5G2e6rJW"
      },
      "source": [
        "**NOTE:** Did not keep all the models that we've fine tuned. Final model that gives best accuracy is located here:  /content/drive/MyDrive/APS360_Project_Group_3/YOLOv5/yolov5x_b15_ep100_run_train282_val61/weights/best.pt\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C-e25dUb8tdB"
      },
      "source": [
        "**Results logged here:** \n",
        "\n",
        "https://wandb.ai/aps360-group3-2021/YOLOv5/reports/FEN-Generator-APS360-Summer-2021-Training-Report-Results--Vmlldzo5ODUzMjY?accessToken=wzxixfsd9pmub4cqhmlsfahkszqpaxerv1xeu3rdfhnbkoi0g5ionlw1zqnjko72"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mOWS5Hws9akL"
      },
      "source": [
        "# Testing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-3Sdi_ZWGWBA"
      },
      "source": [
        "## Run Model through Test Images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BHLXmnHw2_Vf"
      },
      "source": [
        "- Trying a bunch of different command combinations:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RDflVMYdwge_",
        "outputId": "3f2fb882-864d-4556-fb6b-44a6c709ddee"
      },
      "source": [
        "\"\"\" \n",
        "run the detect.py script that comes with YOLOv5 and if you give it a folder of images or an image itself, specify the model you want to run after \n",
        "\n",
        "Additional actions you can specify and modify (from reading the code in the YOLOv5 GitHub):\n",
        "--weights -> (best.pt is a file where the script keeps track of your best model/epoch and runs detect.py based on that -> make sure to change the file location to which model you want to use!)\n",
        "\n",
        "--img -> specifies the size of our images (which is 200x200px)\n",
        "--conf -> is the confidence level of the prediction, only shows the predictions above this confidence level numbers\n",
        "--source -> is where the image you want the model to analyze is located\n",
        "--save-crop -> Will crop and save (as JPEG files) the objects the model has detected with bounding boxes\n",
        "--save-txt -> saves the bounding box coordinates, class predicited, and the confidence of the prediction into txt files\n",
        "\n",
        "\"\"\"\n",
        "!python detect.py --weights /content/drive/MyDrive/APS360_Project_Group_3/YOLOv5/yolov5x_b15_ep100_run_train282_val61/weights/best.pt \\\n",
        "  --img 200 --conf 0.3 --line-thickness 1 --save-txt --save-conf --save-crop \\\n",
        "  --source /content/drive/MyDrive/APS360_Project_Group_3/dataset/annotated/test_annotated \\\n",
        "  --project /content/drive/MyDrive/APS360_Project_Group_3/test_results"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/content/drive/MyDrive/APS360_Project_Group_3/YOLOv5/yolov5x_b15_ep100_run_train282_val61/weights/best.pt'], source=/content/drive/MyDrive/APS360_Project_Group_3/dataset/annotated/test_annotated, imgsz=200, conf_thres=0.3, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=True, save_conf=True, save_crop=True, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=/content/drive/MyDrive/APS360_Project_Group_3/test_results, name=exp, exist_ok=False, line_thickness=1, hide_labels=False, hide_conf=False, half=False\n",
            "YOLOv5 🚀 v5.0-350-gf409d8e torch 1.9.0+cu102 CUDA:0 (Tesla T4, 15109.75MB)\n",
            "\n",
            "Fusing layers... \n",
            "Model Summary: 476 layers, 87272713 parameters, 0 gradients, 217.3 GFLOPs\n",
            "WARNING: --img-size 200 must be multiple of max stride 32, updating to 224\n",
            "image 1/61 /content/drive/MyDrive/APS360_Project_Group_3/dataset/annotated/test_annotated/1B1B3R-8-1b2k3-8-2n5-1rK5-b7-8.jpeg: 224x224 2 b_bs, 2 b_ws, 1 r_b, 1 r_w, 1 n_b, 1 k_b, 1 k_w, Done. (0.041s)\n",
            "image 2/61 /content/drive/MyDrive/APS360_Project_Group_3/dataset/annotated/test_annotated/1B1B4-4R3-2R2p2-K7-8-3b3r-2Q4P-R2k4.jpeg: 224x224 1 p_b, 1 p_w, 1 b_b, 2 b_ws, 4 r_bs, 2 r_ws, 1 k_b, 1 k_w, 1 q_w, Done. (0.029s)\n",
            "image 3/61 /content/drive/MyDrive/APS360_Project_Group_3/dataset/annotated/test_annotated/1B1BK3-7b-3Np3-4N3-2p1r2P-2r5-8-5k1b.jpeg: 224x224 2 p_bs, 1 p_w, 2 b_bs, 2 b_ws, 2 r_bs, 2 n_ws, 1 k_b, 1 k_w, Done. (0.029s)\n",
            "image 4/61 /content/drive/MyDrive/APS360_Project_Group_3/dataset/annotated/test_annotated/1B1K3k-8-8-2r4R-2b5-8-7b-8.jpeg: 224x224 2 b_bs, 1 b_w, 1 r_b, 1 r_w, 1 k_b, 1 k_w, Done. (0.029s)\n",
            "image 5/61 /content/drive/MyDrive/APS360_Project_Group_3/dataset/annotated/test_annotated/1B1K4-1bb3Bb-4P3-5R2-R7-8-8-6k1.jpeg: 224x224 1 p_w, 3 b_bs, 2 b_ws, 2 r_ws, 1 k_b, 1 k_w, Done. (0.029s)\n",
            "image 6/61 /content/drive/MyDrive/APS360_Project_Group_3/dataset/annotated/test_annotated/1B1K4-1p5N-7p-1qp5-n1P5-8-6k1-b7.jpeg: 224x224 3 p_bs, 1 p_w, 1 b_b, 1 b_w, 1 n_b, 1 n_w, 1 k_b, 1 k_w, 1 q_b, Done. (0.029s)\n",
            "image 7/61 /content/drive/MyDrive/APS360_Project_Group_3/dataset/annotated/test_annotated/1B1K4-2b5-8-8-R3R2P-5k2-N3R1r1-1r2RR2.jpeg: 224x224 1 p_w, 1 b_b, 1 b_w, 2 r_bs, 5 r_ws, 1 n_w, 1 k_b, 1 k_w, Done. (0.029s)\n",
            "image 8/61 /content/drive/MyDrive/APS360_Project_Group_3/dataset/annotated/test_annotated/1B1K4-3B4-3p4-8-4k3-6p1-2B5-nq6.jpeg: 224x224 2 p_bs, 3 b_ws, 1 n_b, 1 k_b, 1 k_w, 1 q_b, Done. (0.029s)\n",
            "image 9/61 /content/drive/MyDrive/APS360_Project_Group_3/dataset/annotated/test_annotated/1B1K4-3N1k1P-6Q1-3r1n2-8-3p1NNN-8-3b2rR.jpeg: 224x224 1 p_b, 1 p_w, 1 b_b, 1 b_w, 2 r_bs, 1 r_w, 1 n_b, 4 n_ws, 1 k_b, 1 k_w, 1 q_w, Done. (0.029s)\n",
            "image 10/61 /content/drive/MyDrive/APS360_Project_Group_3/dataset/annotated/test_annotated/1B1K4-3P4-6k1-1p6-6p1-8-7p-3B4.jpeg: 224x224 3 p_bs, 1 p_w, 2 b_ws, 1 k_b, 1 k_w, Done. (0.029s)\n",
            "image 11/61 /content/drive/MyDrive/APS360_Project_Group_3/dataset/annotated/test_annotated/1B1K4-4n3-4P3-8-4Q1r1-3nk3-r7-4N3.jpeg: 224x224 1 p_w, 1 b_w, 2 r_bs, 2 n_bs, 1 n_w, 1 k_b, 1 k_w, 1 q_w, Done. (0.029s)\n",
            "image 12/61 /content/drive/MyDrive/APS360_Project_Group_3/dataset/annotated/test_annotated/1B1K4-6k1-2b2N2-4R3-7B-2pr4-2R1P3-n4n1n.jpeg: 224x224 1 p_b, 1 p_w, 1 b_b, 2 b_ws, 1 r_b, 2 r_ws, 3 n_bs, 1 n_w, 1 k_b, 1 k_w, Done. (0.029s)\n",
            "image 13/61 /content/drive/MyDrive/APS360_Project_Group_3/dataset/annotated/test_annotated/1B1N1B1n-4K2k-2n5-3P4-B7-2b5-2p3N1-rN5n.jpeg: 224x224 1 p_b, 1 p_w, 1 b_b, 3 b_ws, 1 r_b, 3 n_bs, 3 n_ws, 1 k_b, 1 k_w, Done. (0.029s)\n",
            "image 14/61 /content/drive/MyDrive/APS360_Project_Group_3/dataset/annotated/test_annotated/1B1N4-3R4-n2b4-8-8-b2P4-5b2-2K1b2k.jpeg: 224x224 1 p_w, 4 b_bs, 1 b_w, 1 r_w, 1 n_b, 1 n_w, 1 k_b, 1 k_w, Done. (0.029s)\n",
            "image 15/61 /content/drive/MyDrive/APS360_Project_Group_3/dataset/annotated/test_annotated/1B1N4-7k-1rP4N-1b6-6n1-5n2-2Q1K2P-r2B4.jpeg: 224x224 1 p_b, 2 p_ws, 1 b_b, 2 b_ws, 2 r_bs, 2 n_bs, 2 n_ws, 1 k_b, 1 k_w, 1 q_w, Done. (0.029s)\n",
            "image 16/61 /content/drive/MyDrive/APS360_Project_Group_3/dataset/annotated/test_annotated/1B1N4-8-8-1K6-8-8-5N1k-8.jpeg: 224x224 1 b_w, 2 n_ws, 1 k_b, 1 k_w, Done. (0.031s)\n",
            "image 17/61 /content/drive/MyDrive/APS360_Project_Group_3/dataset/annotated/test_annotated/1B1Nk3-3n4-2B5-4bb2-K4B2-4r2p-6R1-1r6.jpeg: 224x224 1 p_b, 2 b_bs, 3 b_ws, 2 r_bs, 1 r_w, 1 n_b, 1 n_w, 1 k_b, 1 k_w, Done. (0.029s)\n",
            "image 18/61 /content/drive/MyDrive/APS360_Project_Group_3/dataset/annotated/test_annotated/1B1Q2B1-8-1K6-8-3k4-6B1-nP3P2-8.jpeg: 224x224 2 p_ws, 3 b_ws, 1 n_b, 1 k_b, 1 k_w, 1 q_w, Done. (0.029s)\n",
            "image 19/61 /content/drive/MyDrive/APS360_Project_Group_3/dataset/annotated/test_annotated/1B1b4-1Q2b3-8-6rn-3NK3-7k-2r5-8.jpeg: 224x224 2 b_bs, 1 b_w, 2 r_bs, 1 n_b, 1 n_w, 1 k_b, 1 k_w, 1 q_w, Done. (0.029s)\n",
            "image 20/61 /content/drive/MyDrive/APS360_Project_Group_3/dataset/annotated/test_annotated/1B1b4-6P1-P2BK3-8-5PR1-nPr5-N4k1P-8.jpeg: 224x224 5 p_ws, 1 b_b, 2 b_ws, 1 r_b, 1 r_w, 1 n_b, 1 n_w, 1 k_b, 1 k_w, Done. (0.029s)\n",
            "image 21/61 /content/drive/MyDrive/APS360_Project_Group_3/dataset/annotated/test_annotated/1B1b4-8-8-2B5-3b4-1B2p1K1-8-6k1.jpeg: 224x224 1 p_b, 2 b_bs, 3 b_ws, 1 k_b, 1 k_w, Done. (0.029s)\n",
            "image 22/61 /content/drive/MyDrive/APS360_Project_Group_3/dataset/annotated/test_annotated/1B1bq2B-1P2R2B-K7-6B1-2N5-5r2-N7-5Rk1.jpeg: 224x224 1 p_w, 1 b_b, 4 b_ws, 1 r_b, 2 r_ws, 2 n_ws, 1 k_b, 1 k_w, 1 q_b, Done. (0.029s)\n",
            "image 23/61 /content/drive/MyDrive/APS360_Project_Group_3/dataset/annotated/test_annotated/1B1n1r2-8-8-1n5b-3r4-8-5k2-2K5.jpeg: 224x224 1 b_b, 1 b_w, 2 r_bs, 2 n_bs, 1 k_b, 1 k_w, Done. (0.029s)\n",
            "image 24/61 /content/drive/MyDrive/APS360_Project_Group_3/dataset/annotated/test_annotated/1B1n2r1-R5r1-p4P1P-5p2-2Br4-B7-7k-4K1B1.jpeg: 224x224 2 p_bs, 2 p_ws, 4 b_ws, 3 r_bs, 1 r_w, 1 n_b, 1 k_b, 1 k_w, Done. (0.029s)\n",
            "image 25/61 /content/drive/MyDrive/APS360_Project_Group_3/dataset/annotated/test_annotated/1B1n4-2p1b3-P1K1PBR1-2b4k-6B1-8-8-BN6.jpeg: 224x224 2 p_bs, 2 p_ws, 2 b_bs, 4 b_ws, 1 r_b, 1 n_b, 1 n_w, 1 k_b, 1 k_w, Done. (0.031s)\n",
            "image 26/61 /content/drive/MyDrive/APS360_Project_Group_3/dataset/annotated/test_annotated/1B1n4-3QB2R-R1K4k-2n5-2Q4n-6b1-1P6-6B1.jpeg: 224x224 1 p_w, 1 b_b, 3 b_ws, 2 r_ws, 3 n_bs, 1 k_b, 1 k_w, 2 q_ws, Done. (0.029s)\n",
            "image 27/61 /content/drive/MyDrive/APS360_Project_Group_3/dataset/annotated/test_annotated/1B1nR3-1K6-8-1R6-2P1k1n1-2P4p-5B2-6qb.jpeg: 224x224 1 p_b, 2 p_ws, 1 b_b, 2 b_ws, 2 r_ws, 2 n_bs, 1 k_b, 1 k_w, 1 q_b, Done. (0.029s)\n",
            "image 28/61 /content/drive/MyDrive/APS360_Project_Group_3/dataset/annotated/test_annotated/1B1nkB2-1K6-3p2p1-8-P2b4-8-8-3N4.jpeg: 224x224 2 p_bs, 1 p_w, 1 b_b, 2 b_ws, 1 n_b, 1 n_w, 1 k_b, 1 k_w, Done. (0.030s)\n",
            "image 29/61 /content/drive/MyDrive/APS360_Project_Group_3/dataset/annotated/test_annotated/1b1B4-1P6-2B5-3r2kN-2r4P-8-5K2-3B4.jpeg: 224x224 2 p_ws, 1 b_b, 3 b_ws, 2 r_bs, 1 n_w, 1 k_b, 1 k_w, Done. (0.030s)\n",
            "image 30/61 /content/drive/MyDrive/APS360_Project_Group_3/dataset/annotated/test_annotated/1b1B4-1p4P1-5k2-1n3q2-8-2B5-1K3rR1-2q5.jpeg: 224x224 1 p_b, 1 p_w, 1 b_b, 2 b_ws, 1 r_b, 1 r_w, 1 n_b, 1 k_b, 1 k_w, 2 q_bs, Done. (0.029s)\n",
            "image 31/61 /content/drive/MyDrive/APS360_Project_Group_3/dataset/annotated/test_annotated/1b1B4-2b3PK-7P-8-1BP4k-4P3-8-8.jpeg: 224x224 4 p_ws, 2 b_bs, 2 b_ws, 1 k_b, 1 k_w, Done. (0.030s)\n",
            "image 32/61 /content/drive/MyDrive/APS360_Project_Group_3/dataset/annotated/test_annotated/1b1B4-3b1PPn-8-6b1-n2R3r-2K5-8-3Rk3.jpeg: 224x224 2 p_ws, 3 b_bs, 1 b_w, 1 r_b, 2 r_ws, 2 n_bs, 1 k_b, 1 k_w, Done. (0.029s)\n",
            "image 33/61 /content/drive/MyDrive/APS360_Project_Group_3/dataset/annotated/test_annotated/1b1B4-8-K3N3-b1B5-8-k4P2-8-3n1B2.jpeg: 224x224 1 p_w, 2 b_bs, 3 b_ws, 1 n_b, 1 n_w, 1 k_b, 1 k_w, Done. (0.029s)\n",
            "image 34/61 /content/drive/MyDrive/APS360_Project_Group_3/dataset/annotated/test_annotated/1b1K1B2-2p5-b2n4-6k1-8-5rN1-2b5-8.jpeg: 224x224 1 p_b, 3 b_bs, 1 b_w, 1 r_b, 1 n_b, 1 n_w, 1 k_b, 1 k_w, Done. (0.029s)\n",
            "image 35/61 /content/drive/MyDrive/APS360_Project_Group_3/dataset/annotated/test_annotated/1b1K2R1-5PR1-7p-6p1-4k3-8-6b1-8.jpeg: 224x224 2 p_bs, 1 p_w, 2 b_bs, 2 r_ws, 1 k_b, 1 k_w, Done. (0.029s)\n",
            "image 36/61 /content/drive/MyDrive/APS360_Project_Group_3/dataset/annotated/test_annotated/1b1K4-8-1NR1P3-8-5B2-8-7k-8.jpeg: 224x224 1 p_w, 1 b_b, 1 b_w, 1 r_w, 1 n_w, 1 k_b, 1 k_w, Done. (0.029s)\n",
            "image 37/61 /content/drive/MyDrive/APS360_Project_Group_3/dataset/annotated/test_annotated/1b1K4-8-2R2B2-3qk2n-8-1B6-R4P2-4Q3.jpeg: 224x224 1 p_w, 1 b_b, 2 b_ws, 2 r_ws, 1 n_b, 1 k_b, 1 k_w, 1 q_b, 1 q_w, Done. (0.029s)\n",
            "image 38/61 /content/drive/MyDrive/APS360_Project_Group_3/dataset/annotated/test_annotated/1b1K4-R5k1-4r2N-8-8-8-8-Q7.jpeg: 224x224 1 p_b, 1 b_b, 1 r_b, 1 r_w, 1 n_w, 1 k_b, 2 k_ws, Done. (0.029s)\n",
            "image 39/61 /content/drive/MyDrive/APS360_Project_Group_3/dataset/annotated/test_annotated/1b1KN3-7B-2R5-4kr1r-1Q6-2Q1pr2-2B5-4n3.jpeg: 224x224 1 p_b, 1 b_b, 2 b_ws, 3 r_bs, 1 r_w, 1 n_b, 1 n_w, 1 k_b, 1 k_w, 2 q_ws, Done. (0.029s)\n",
            "image 40/61 /content/drive/MyDrive/APS360_Project_Group_3/dataset/annotated/test_annotated/1b1Kq3-P3p3-2pnQ3-2b5-8-r4p2-3p4-3B3k.jpeg: 224x224 4 p_bs, 1 p_w, 2 b_bs, 1 b_w, 1 r_b, 1 n_b, 1 k_b, 1 k_w, 1 q_b, 1 q_w, Done. (0.029s)\n",
            "image 41/61 /content/drive/MyDrive/APS360_Project_Group_3/dataset/annotated/test_annotated/1b1N4-3K4-8-8-1N6-2r1r2k-8-8.jpeg: 224x224 1 b_b, 2 r_bs, 2 n_ws, 1 k_b, 1 k_w, Done. (0.029s)\n",
            "image 42/61 /content/drive/MyDrive/APS360_Project_Group_3/dataset/annotated/test_annotated/1b1N4-5K1k-3p4-3r2b1-1n6-8-3r1n2-2QQ4.jpeg: 224x224 1 p_b, 2 b_bs, 2 r_bs, 2 n_bs, 1 n_w, 1 k_b, 1 k_w, 2 q_ws, Done. (0.029s)\n",
            "image 43/61 /content/drive/MyDrive/APS360_Project_Group_3/dataset/annotated/test_annotated/1b1N4-7k-4b3-8-8-8-3P4-3K4.jpeg: 224x224 1 p_w, 2 b_bs, 1 n_w, 1 k_b, 1 k_w, Done. (0.029s)\n",
            "image 44/61 /content/drive/MyDrive/APS360_Project_Group_3/dataset/annotated/test_annotated/1b1N4-8-2K5-1nr2p2-Nn6-1RQ5-8-R5rk.jpeg: 224x224 1 p_b, 1 b_b, 2 r_bs, 2 r_ws, 2 n_bs, 2 n_ws, 1 k_b, 1 k_w, 1 q_w, Done. (0.029s)\n",
            "image 45/61 /content/drive/MyDrive/APS360_Project_Group_3/dataset/annotated/test_annotated/1b1N4-8-8-2N1N3-P7-p7-4r1k1-3K4.jpeg: 224x224 2 p_bs, 1 p_w, 1 b_b, 1 r_b, 3 n_ws, 1 k_b, 1 k_w, Done. (0.029s)\n",
            "image 46/61 /content/drive/MyDrive/APS360_Project_Group_3/dataset/annotated/test_annotated/1b1N4-8-8-7k-3K1Pp1-8-8-3B4.jpeg: 224x224 1 p_b, 1 p_w, 1 b_b, 1 b_w, 1 n_w, 1 k_b, 1 k_w, Done. (0.029s)\n",
            "image 47/61 /content/drive/MyDrive/APS360_Project_Group_3/dataset/annotated/test_annotated/1b1NN3-3N3p-3k4-8-1K4b1-2R5-5r2-5N1B.jpeg: 224x224 1 p_b, 2 b_bs, 1 b_w, 1 r_b, 1 r_w, 4 n_ws, 1 k_b, 2 k_ws, Done. (0.029s)\n",
            "image 48/61 /content/drive/MyDrive/APS360_Project_Group_3/dataset/annotated/test_annotated/1b1Q1B1R-8-r7-K2n4-q7-1P2k2N-8-BQ2N3.jpeg: 224x224 1 p_w, 1 b_b, 2 b_ws, 1 r_b, 1 r_w, 1 n_b, 2 n_ws, 1 k_b, 1 k_w, 1 q_b, 2 q_ws, Done. (0.029s)\n",
            "image 49/61 /content/drive/MyDrive/APS360_Project_Group_3/dataset/annotated/test_annotated/1b1Q4-3K1NP1-B7-8-R4N2-3r4-4q3-1N1k4.jpeg: 224x224 1 p_w, 1 b_b, 1 b_w, 1 r_b, 1 r_w, 3 n_ws, 1 k_b, 1 k_w, 1 q_b, 1 q_w, Done. (0.029s)\n",
            "image 50/61 /content/drive/MyDrive/APS360_Project_Group_3/dataset/annotated/test_annotated/1b1b4-1N5r-1P1p3B-8-3KP3-3P2k1-3PB3-1N6.jpeg: 224x224 1 p_b, 4 p_ws, 2 b_bs, 2 b_ws, 1 r_b, 2 n_ws, 1 k_b, 1 k_w, Done. (0.029s)\n",
            "image 51/61 /content/drive/MyDrive/APS360_Project_Group_3/dataset/annotated/test_annotated/1b1b4-3q4-n6k-3b3R-Q7-1K3p2-1n6-1N3QRb.jpeg: 224x224 1 p_b, 4 b_bs, 2 b_ws, 2 r_ws, 2 n_bs, 1 n_w, 1 k_b, 1 k_w, 1 q_b, 2 q_ws, Done. (0.029s)\n",
            "image 52/61 /content/drive/MyDrive/APS360_Project_Group_3/dataset/annotated/test_annotated/1b1b4-Kn6-2Pk4-8-5p2-7n-7n-8.jpeg: 224x224 1 p_b, 1 p_w, 2 b_bs, 3 n_bs, 1 k_b, 1 k_w, Done. (0.029s)\n",
            "image 53/61 /content/drive/MyDrive/APS360_Project_Group_3/dataset/annotated/test_annotated/1b1bB3-8-1P4k1-8-8-2K3r1-8-5bQ1.jpeg: 224x224 1 p_w, 3 b_bs, 1 b_w, 1 r_b, 1 k_b, 1 k_w, 1 q_w, Done. (0.029s)\n",
            "image 54/61 /content/drive/MyDrive/APS360_Project_Group_3/dataset/annotated/test_annotated/1b1bK3-8-8-7r-1p5B-r4NkQ-8-6N1.jpeg: 224x224 1 p_b, 2 b_bs, 1 b_w, 2 r_bs, 2 n_ws, 1 k_b, 1 k_w, 1 q_w, Done. (0.029s)\n",
            "image 55/61 /content/drive/MyDrive/APS360_Project_Group_3/dataset/annotated/test_annotated/1b1k3N-8-5P2-N2p2N1-8-1Q6-3N4-K1Q3r1.jpeg: 224x224 1 p_b, 1 p_w, 1 b_b, 1 r_b, 4 n_ws, 1 k_b, 1 k_w, 2 q_ws, Done. (0.029s)\n",
            "image 56/61 /content/drive/MyDrive/APS360_Project_Group_3/dataset/annotated/test_annotated/1b1n2B1-3K3N-7N-8-3pB3-P2N4-1Qrk4-n4n2.jpeg: 224x224 1 p_b, 1 p_w, 1 b_b, 2 b_ws, 1 r_b, 3 n_bs, 3 n_ws, 1 k_b, 1 k_w, 1 q_w, Done. (0.029s)\n",
            "image 57/61 /content/drive/MyDrive/APS360_Project_Group_3/dataset/annotated/test_annotated/1b1n4-3q4-6n1-8-5K2-3Q4-8-1r5k.jpeg: 224x224 1 b_b, 1 r_b, 2 n_bs, 1 k_b, 1 k_w, 1 q_b, 1 q_w, Done. (0.029s)\n",
            "image 58/61 /content/drive/MyDrive/APS360_Project_Group_3/dataset/annotated/test_annotated/1b1n4-4BKP1-8-1r5n-3p1k2-3p4-3P4-6r1.jpeg: 224x224 2 p_bs, 2 p_ws, 1 b_b, 1 b_w, 2 r_bs, 2 n_bs, 1 k_b, 1 k_w, Done. (0.029s)\n",
            "image 59/61 /content/drive/MyDrive/APS360_Project_Group_3/dataset/annotated/test_annotated/1b1n4-N7-7R-8-2K1p1p1-N3b3-B1p2PP1-3k4.jpeg: 224x224 3 p_bs, 2 p_ws, 2 b_bs, 1 b_w, 1 r_w, 1 n_b, 2 n_ws, 1 k_b, 1 k_w, Done. (0.029s)\n",
            "image 60/61 /content/drive/MyDrive/APS360_Project_Group_3/dataset/annotated/test_annotated/1b1nr3-p3N3-Bp6-1q6-2K1k3-B7-1P6-N7.jpeg: 224x224 2 p_bs, 1 p_w, 1 b_b, 2 b_ws, 1 r_b, 1 n_b, 2 n_ws, 1 k_b, 1 k_w, 1 q_b, Done. (0.029s)\n",
            "image 61/61 /content/drive/MyDrive/APS360_Project_Group_3/dataset/annotated/test_annotated/1b1qb3-4r3-5k2-8-8-2R5-8-2K5.jpeg: 224x224 2 b_bs, 1 r_b, 1 r_w, 2 k_bs, 1 k_w, 1 q_b, Done. (0.029s)\n",
            "Results saved to \u001b[1m/content/drive/MyDrive/APS360_Project_Group_3/test_results/exp5\u001b[0m\n",
            "61 labels saved to /content/drive/MyDrive/APS360_Project_Group_3/test_results/exp5/labels\n",
            "Done. (36.576s)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f0uIB9EoNhKx",
        "outputId": "b116d19d-9818-4d2d-81d1-5c5b563a811a"
      },
      "source": [
        "!python export.py --weights /content/drive/MyDrive/APS360_Project_Group_3/YOLOv5/yolov5x_b15_ep100_run_train282_val61/weights/best.pt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mexport: \u001b[0mweights=/content/drive/MyDrive/APS360_Project_Group_3/YOLOv5/yolov5x_b15_ep100_run_train282_val61/weights/best.pt, img_size=[640, 640], batch_size=1, device=cpu, include=['torchscript', 'onnx', 'coreml'], half=False, inplace=False, train=False, optimize=False, dynamic=False, simplify=False, opset=12\n",
            "YOLOv5 🚀 v5.0-350-gf409d8e torch 1.9.0+cu102 CPU\n",
            "\n",
            "Fusing layers... \n",
            "Model Summary: 476 layers, 87272713 parameters, 0 gradients, 217.3 GFLOPs\n",
            "\n",
            "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from /content/drive/MyDrive/APS360_Project_Group_3/YOLOv5/yolov5x_b15_ep100_run_train282_val61/weights/best.pt (175.2 MB)\n",
            "\n",
            "\u001b[34m\u001b[1mTorchScript:\u001b[0m starting export with torch 1.9.0+cu102...\n",
            "/content/yolov5/yolov5/yolov5/yolov5/models/yolo.py:57: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
            "  if self.grid[i].shape[2:4] != x[i].shape[2:4] or self.onnx_dynamic:\n",
            "/content/yolov5/yolov5/yolov5/yolov5/models/yolo.py:57: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
            "  if self.grid[i].shape[2:4] != x[i].shape[2:4] or self.onnx_dynamic:\n",
            "\u001b[34m\u001b[1mTorchScript:\u001b[0m export success, saved as /content/drive/MyDrive/APS360_Project_Group_3/YOLOv5/yolov5x_b15_ep100_run_train282_val61/weights/best.torchscript.pt (349.8 MB)\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m onnx not found and is required by YOLOv5, attempting auto-update...\n",
            "Collecting onnx\n",
            "  Downloading onnx-1.10.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (12.3 MB)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from onnx) (3.17.3)\n",
            "Requirement already satisfied: typing-extensions>=3.6.2.1 in /usr/local/lib/python3.7/dist-packages (from onnx) (3.7.4.3)\n",
            "Requirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.7/dist-packages (from onnx) (1.19.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from onnx) (1.15.0)\n",
            "Installing collected packages: onnx\n",
            "Successfully installed onnx-1.10.1\n",
            "\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m onnx-simplifier not found and is required by YOLOv5, attempting auto-update...\n",
            "Collecting onnx-simplifier\n",
            "  Downloading onnx-simplifier-0.3.6.tar.gz (13 kB)\n",
            "Requirement already satisfied: onnx in /usr/local/lib/python3.7/dist-packages (from onnx-simplifier) (1.10.1)\n",
            "Collecting onnxoptimizer>=0.2.5\n",
            "  Downloading onnxoptimizer-0.2.6-cp37-cp37m-manylinux2014_x86_64.whl (466 kB)\n",
            "Collecting onnxruntime>=1.6.0\n",
            "  Downloading onnxruntime-1.8.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.5 MB)\n",
            "Requirement already satisfied: protobuf>=3.7.0 in /usr/local/lib/python3.7/dist-packages (from onnx-simplifier) (3.17.3)\n",
            "Requirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.7/dist-packages (from onnxruntime>=1.6.0->onnx-simplifier) (1.19.5)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.7/dist-packages (from onnxruntime>=1.6.0->onnx-simplifier) (1.12)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.7.0->onnx-simplifier) (1.15.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.2.1 in /usr/local/lib/python3.7/dist-packages (from onnx->onnx-simplifier) (3.7.4.3)\n",
            "Building wheels for collected packages: onnx-simplifier\n",
            "  Building wheel for onnx-simplifier (setup.py): started\n",
            "  Building wheel for onnx-simplifier (setup.py): finished with status 'done'\n",
            "  Created wheel for onnx-simplifier: filename=onnx_simplifier-0.3.6-py3-none-any.whl size=12874 sha256=fd7ebdbd243654d139d4da832481af4dcd7a07acaefb9263545c897c108e8635\n",
            "  Stored in directory: /root/.cache/pip/wheels/0c/47/80/8eb21098e22c19d60b1c14021ee67442b4ad2d7991fdad46ba\n",
            "Successfully built onnx-simplifier\n",
            "Installing collected packages: onnxruntime, onnxoptimizer, onnx-simplifier\n",
            "Successfully installed onnx-simplifier-0.3.6 onnxoptimizer-0.2.6 onnxruntime-1.8.1\n",
            "\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m 2 packages updated per ['onnx', 'onnx-simplifier']\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m ⚠️ \u001b[1mRestart runtime or rerun command for updates to take effect\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.10.1...\n",
            "/content/yolov5/yolov5/yolov5/yolov5/models/yolo.py:57: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
            "  if self.grid[i].shape[2:4] != x[i].shape[2:4] or self.onnx_dynamic:\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m export success, saved as /content/drive/MyDrive/APS360_Project_Group_3/YOLOv5/yolov5x_b15_ep100_run_train282_val61/weights/best.onnx (349.2 MB)\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m run --dynamic ONNX model inference with detect.py: 'python detect.py --weights /content/drive/MyDrive/APS360_Project_Group_3/YOLOv5/yolov5x_b15_ep100_run_train282_val61/weights/best.onnx'\n",
            "\n",
            "\u001b[34m\u001b[1mCoreML:\u001b[0m export failure: No module named 'coremltools'\n",
            "\n",
            "Export complete (43.11s)\n",
            "Results saved to \u001b[1m/content/drive/.shortcut-targets-by-id/1UNJmbCiZ3kddYnfAvuza34WMmvVxQCWq/APS360_Project_Group_3/YOLOv5/yolov5x_b15_ep100_run_train282_val61/weights\u001b[0m\n",
            "Visualize with https://netron.app\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RpH02Tx4G4NH",
        "outputId": "88cce1dc-dbb3-4a60-bfd3-adccd8b40246"
      },
      "source": [
        "!python detect.py --weights /content/drive/MyDrive/APS360_Project_Group_3/YOLOv5/yolov5x_b15_ep100_run_train282_val61/weights/best.pt \\\n",
        "--data /content/yolov5/FEN.yaml --iou-thres 0.5 \\\n",
        " --task test --source"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "usage: detect.py [-h] [--weights WEIGHTS [WEIGHTS ...]] [--source SOURCE]\n",
            "                 [--imgsz IMGSZ] [--conf-thres CONF_THRES]\n",
            "                 [--iou-thres IOU_THRES] [--max-det MAX_DET] [--device DEVICE]\n",
            "                 [--view-img] [--save-txt] [--save-conf] [--save-crop]\n",
            "                 [--nosave] [--classes CLASSES [CLASSES ...]] [--agnostic-nms]\n",
            "                 [--augment] [--visualize] [--update] [--project PROJECT]\n",
            "                 [--name NAME] [--exist-ok] [--line-thickness LINE_THICKNESS]\n",
            "                 [--hide-labels] [--hide-conf] [--half]\n",
            "detect.py: error: argument --source: expected one argument\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dKEeqf83K503",
        "outputId": "368f5085-e2a9-45c5-88d5-8079f4eb886f"
      },
      "source": [
        "!python detect.py --weights /content/drive/MyDrive/APS360_Project_Group_3/YOLOv5/yolov5x_b15_ep100_run_train282_val61/weights/best.pt \\\n",
        "  --save-txt --save-conf --iou-thres 0.5 \\\n",
        "  --source /content/drive/MyDrive/APS360_Project_Group_3/dataset/annotated/test_annotated \\\n",
        "  --project /content/drive/MyDrive/APS360_Project_Group_3/test_results"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/content/drive/MyDrive/APS360_Project_Group_3/YOLOv5/yolov5x_b15_ep100_run_train282_val61/weights/best.pt'], source=/content/drive/MyDrive/APS360_Project_Group_3/dataset/annotated/test_annotated, imgsz=640, conf_thres=0.25, iou_thres=0.5, max_det=1000, device=, view_img=False, save_txt=True, save_conf=True, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=/content/drive/MyDrive/APS360_Project_Group_3/test_results, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False\n",
            "YOLOv5 🚀 v5.0-350-gf409d8e torch 1.9.0+cu102 CUDA:0 (Tesla T4, 15109.75MB)\n",
            "\n",
            "Fusing layers... \n",
            "Model Summary: 476 layers, 87272713 parameters, 0 gradients, 217.3 GFLOPs\n",
            "image 1/61 /content/drive/MyDrive/APS360_Project_Group_3/dataset/annotated/test_annotated/1B1B3R-8-1b2k3-8-2n5-1rK5-b7-8.jpeg: 640x640 2 b_bs, 2 b_ws, 1 r_b, 1 r_w, 1 n_b, 1 k_b, 1 k_w, Done. (0.069s)\n",
            "image 2/61 /content/drive/MyDrive/APS360_Project_Group_3/dataset/annotated/test_annotated/1B1B4-4R3-2R2p2-K7-8-3b3r-2Q4P-R2k4.jpeg: 640x640 4 b_bs, 3 b_ws, 1 r_b, 2 r_ws, 4 k_bs, 1 k_w, 1 q_w, Done. (0.068s)\n",
            "image 3/61 /content/drive/MyDrive/APS360_Project_Group_3/dataset/annotated/test_annotated/1B1BK3-7b-3Np3-4N3-2p1r2P-2r5-8-5k1b.jpeg: 640x640 1 p_b, 1 p_w, 4 b_bs, 5 b_ws, 2 r_bs, 2 n_ws, 1 k_b, 1 k_w, Done. (0.055s)\n",
            "image 4/61 /content/drive/MyDrive/APS360_Project_Group_3/dataset/annotated/test_annotated/1B1K3k-8-8-2r4R-2b5-8-7b-8.jpeg: 640x640 2 b_bs, 2 b_ws, 1 r_b, 1 r_w, 1 n_b, 2 k_bs, 1 k_w, Done. (0.055s)\n",
            "image 5/61 /content/drive/MyDrive/APS360_Project_Group_3/dataset/annotated/test_annotated/1B1K4-1bb3Bb-4P3-5R2-R7-8-8-6k1.jpeg: 640x640 3 b_bs, 3 b_ws, 2 r_ws, 1 k_b, 1 k_w, Done. (0.056s)\n",
            "image 6/61 /content/drive/MyDrive/APS360_Project_Group_3/dataset/annotated/test_annotated/1B1K4-1p5N-7p-1qp5-n1P5-8-6k1-b7.jpeg: 640x640 3 p_bs, 1 p_w, 2 b_bs, 2 b_ws, 2 n_bs, 1 n_w, 1 k_b, 1 k_w, 1 q_b, Done. (0.056s)\n",
            "image 7/61 /content/drive/MyDrive/APS360_Project_Group_3/dataset/annotated/test_annotated/1B1K4-2b5-8-8-R3R2P-5k2-N3R1r1-1r2RR2.jpeg: 640x640 1 p_w, 1 b_b, 1 b_w, 2 r_bs, 6 r_ws, 1 n_w, 2 k_bs, 1 k_w, Done. (0.056s)\n",
            "image 8/61 /content/drive/MyDrive/APS360_Project_Group_3/dataset/annotated/test_annotated/1B1K4-3B4-3p4-8-4k3-6p1-2B5-nq6.jpeg: 640x640 2 p_bs, 1 b_b, 5 b_ws, 1 n_b, 1 k_b, 1 k_w, 1 q_b, Done. (0.054s)\n",
            "image 9/61 /content/drive/MyDrive/APS360_Project_Group_3/dataset/annotated/test_annotated/1B1K4-3N1k1P-6Q1-3r1n2-8-3p1NNN-8-3b2rR.jpeg: 640x640 1 p_w, 4 b_bs, 3 b_ws, 2 r_bs, 1 r_w, 2 n_bs, 5 n_ws, 3 k_bs, 1 k_w, 1 q_w, Done. (0.056s)\n",
            "image 10/61 /content/drive/MyDrive/APS360_Project_Group_3/dataset/annotated/test_annotated/1B1K4-3P4-6k1-1p6-6p1-8-7p-3B4.jpeg: 640x640 3 p_bs, 3 b_ws, 1 r_w, 1 n_b, 1 k_b, 1 k_w, Done. (0.055s)\n",
            "image 11/61 /content/drive/MyDrive/APS360_Project_Group_3/dataset/annotated/test_annotated/1B1K4-4n3-4P3-8-4Q1r1-3nk3-r7-4N3.jpeg: 640x640 1 p_w, 1 b_w, 2 r_bs, 3 n_bs, 3 k_bs, 1 q_w, Done. (0.057s)\n",
            "image 12/61 /content/drive/MyDrive/APS360_Project_Group_3/dataset/annotated/test_annotated/1B1K4-6k1-2b2N2-4R3-7B-2pr4-2R1P3-n4n1n.jpeg: 640x640 1 p_b, 1 p_w, 1 b_b, 3 b_ws, 1 r_b, 2 r_ws, 6 n_bs, 1 n_w, 2 k_bs, 3 k_ws, Done. (0.054s)\n",
            "image 13/61 /content/drive/MyDrive/APS360_Project_Group_3/dataset/annotated/test_annotated/1B1N1B1n-4K2k-2n5-3P4-B7-2b5-2p3N1-rN5n.jpeg: 640x640 1 p_b, 1 p_w, 1 b_b, 3 b_ws, 1 r_b, 5 n_bs, 4 n_ws, 1 k_b, 1 k_w, Done. (0.050s)\n",
            "image 14/61 /content/drive/MyDrive/APS360_Project_Group_3/dataset/annotated/test_annotated/1B1N4-3R4-n2b4-8-8-b2P4-5b2-2K1b2k.jpeg: 640x640 2 p_ws, 4 b_bs, 2 b_ws, 1 r_w, 2 n_bs, 1 n_w, 2 k_bs, 1 k_w, Done. (0.055s)\n",
            "image 15/61 /content/drive/MyDrive/APS360_Project_Group_3/dataset/annotated/test_annotated/1B1N4-7k-1rP4N-1b6-6n1-5n2-2Q1K2P-r2B4.jpeg: 640x640 2 p_bs, 1 b_b, 2 b_ws, 2 r_bs, 6 n_bs, 2 k_bs, 1 k_w, Done. (0.055s)\n",
            "image 16/61 /content/drive/MyDrive/APS360_Project_Group_3/dataset/annotated/test_annotated/1B1N4-8-8-1K6-8-8-5N1k-8.jpeg: 640x640 1 b_w, 3 n_ws, 1 k_b, 2 k_ws, Done. (0.056s)\n",
            "image 17/61 /content/drive/MyDrive/APS360_Project_Group_3/dataset/annotated/test_annotated/1B1Nk3-3n4-2B5-4bb2-K4B2-4r2p-6R1-1r6.jpeg: 640x640 1 p_b, 2 b_bs, 3 b_ws, 2 r_bs, 1 r_w, 3 n_bs, 1 n_w, 1 k_b, 1 k_w, Done. (0.056s)\n",
            "image 18/61 /content/drive/MyDrive/APS360_Project_Group_3/dataset/annotated/test_annotated/1B1Q2B1-8-1K6-8-3k4-6B1-nP3P2-8.jpeg: 640x640 1 p_b, 1 p_w, 5 b_ws, 1 n_b, 2 k_ws, 1 q_w, Done. (0.055s)\n",
            "image 19/61 /content/drive/MyDrive/APS360_Project_Group_3/dataset/annotated/test_annotated/1B1b4-1Q2b3-8-6rn-3NK3-7k-2r5-8.jpeg: 640x640 2 b_bs, 1 b_w, 2 r_bs, 1 n_b, 1 n_w, 1 k_b, 1 k_w, 1 q_w, Done. (0.056s)\n",
            "image 20/61 /content/drive/MyDrive/APS360_Project_Group_3/dataset/annotated/test_annotated/1B1b4-6P1-P2BK3-8-5PR1-nPr5-N4k1P-8.jpeg: 640x640 2 b_bs, 8 b_ws, 1 r_w, 2 n_bs, Done. (0.057s)\n",
            "image 21/61 /content/drive/MyDrive/APS360_Project_Group_3/dataset/annotated/test_annotated/1B1b4-8-8-2B5-3b4-1B2p1K1-8-6k1.jpeg: 640x640 2 b_bs, 6 b_ws, 1 r_b, 1 k_b, Done. (0.055s)\n",
            "image 22/61 /content/drive/MyDrive/APS360_Project_Group_3/dataset/annotated/test_annotated/1B1bq2B-1P2R2B-K7-6B1-2N5-5r2-N7-5Rk1.jpeg: 640x640 1 p_w, 1 b_b, 8 b_ws, 1 r_b, 2 r_ws, 3 n_ws, 3 k_bs, 1 q_b, 1 q_w, Done. (0.056s)\n",
            "image 23/61 /content/drive/MyDrive/APS360_Project_Group_3/dataset/annotated/test_annotated/1B1n1r2-8-8-1n5b-3r4-8-5k2-2K5.jpeg: 640x640 1 b_b, 1 b_w, 1 r_b, 2 n_bs, 3 k_bs, 1 k_w, Done. (0.055s)\n",
            "image 24/61 /content/drive/MyDrive/APS360_Project_Group_3/dataset/annotated/test_annotated/1B1n2r1-R5r1-p4P1P-5p2-2Br4-B7-7k-4K1B1.jpeg: 640x640 3 p_bs, 2 b_bs, 6 b_ws, 1 r_w, 1 n_b, 1 k_b, 5 k_ws, Done. (0.055s)\n",
            "image 25/61 /content/drive/MyDrive/APS360_Project_Group_3/dataset/annotated/test_annotated/1B1n4-2p1b3-P1K1PBR1-2b4k-6B1-8-8-BN6.jpeg: 640x640 3 p_bs, 7 b_bs, 1 r_b, 7 n_bs, 1 n_w, 6 k_bs, Done. (0.055s)\n",
            "image 26/61 /content/drive/MyDrive/APS360_Project_Group_3/dataset/annotated/test_annotated/1B1n4-3QB2R-R1K4k-2n5-2Q4n-6b1-1P6-6B1.jpeg: 640x640 1 p_w, 1 b_b, 7 b_ws, 2 r_ws, 3 n_bs, 1 k_b, 1 k_w, 3 q_ws, Done. (0.054s)\n",
            "image 27/61 /content/drive/MyDrive/APS360_Project_Group_3/dataset/annotated/test_annotated/1B1nR3-1K6-8-1R6-2P1k1n1-2P4p-5B2-6qb.jpeg: 640x640 1 p_b, 2 p_ws, 2 b_bs, 4 b_ws, 2 r_ws, 2 n_bs, 1 k_b, 1 k_w, Done. (0.055s)\n",
            "image 28/61 /content/drive/MyDrive/APS360_Project_Group_3/dataset/annotated/test_annotated/1B1nkB2-1K6-3p2p1-8-P2b4-8-8-3N4.jpeg: 640x640 4 b_bs, 4 b_ws, 1 r_w, 6 n_bs, 2 n_ws, 2 k_bs, Done. (0.056s)\n",
            "image 29/61 /content/drive/MyDrive/APS360_Project_Group_3/dataset/annotated/test_annotated/1b1B4-1P6-2B5-3r2kN-2r4P-8-5K2-3B4.jpeg: 640x640 2 p_ws, 1 b_b, 7 b_ws, 2 r_bs, 1 n_w, 1 k_b, 1 k_w, Done. (0.054s)\n",
            "image 30/61 /content/drive/MyDrive/APS360_Project_Group_3/dataset/annotated/test_annotated/1b1B4-1p4P1-5k2-1n3q2-8-2B5-1K3rR1-2q5.jpeg: 640x640 1 p_b, 1 p_w, 3 b_bs, 2 b_ws, 1 r_b, 1 r_w, 2 n_bs, 1 k_b, 1 k_w, 2 q_bs, Done. (0.054s)\n",
            "image 31/61 /content/drive/MyDrive/APS360_Project_Group_3/dataset/annotated/test_annotated/1b1B4-2b3PK-7P-8-1BP4k-4P3-8-8.jpeg: 640x640 7 p_ws, 2 b_bs, 8 b_ws, 1 n_b, 2 k_bs, 1 k_w, Done. (0.057s)\n",
            "image 32/61 /content/drive/MyDrive/APS360_Project_Group_3/dataset/annotated/test_annotated/1b1B4-3b1PPn-8-6b1-n2R3r-2K5-8-3Rk3.jpeg: 640x640 1 p_b, 3 b_bs, 2 b_ws, 1 r_b, 2 r_ws, 5 n_bs, 1 k_b, 1 k_w, Done. (0.058s)\n",
            "image 33/61 /content/drive/MyDrive/APS360_Project_Group_3/dataset/annotated/test_annotated/1b1B4-8-K3N3-b1B5-8-k4P2-8-3n1B2.jpeg: 640x640 1 p_w, 5 b_bs, 4 b_ws, 3 n_bs, 1 n_w, 1 k_w, 1 q_b, Done. (0.058s)\n",
            "image 34/61 /content/drive/MyDrive/APS360_Project_Group_3/dataset/annotated/test_annotated/1b1K1B2-2p5-b2n4-6k1-8-5rN1-2b5-8.jpeg: 640x640 1 p_b, 4 b_bs, 4 n_bs, 2 n_ws, 3 k_bs, 1 k_w, Done. (0.055s)\n",
            "image 35/61 /content/drive/MyDrive/APS360_Project_Group_3/dataset/annotated/test_annotated/1b1K2R1-5PR1-7p-6p1-4k3-8-6b1-8.jpeg: 640x640 3 p_bs, 2 b_bs, 2 r_ws, 2 k_bs, 1 k_w, Done. (0.056s)\n",
            "image 36/61 /content/drive/MyDrive/APS360_Project_Group_3/dataset/annotated/test_annotated/1b1K4-8-1NR1P3-8-5B2-8-7k-8.jpeg: 640x640 1 p_w, 1 b_b, 3 b_ws, 1 r_w, 1 n_w, 1 k_b, 1 k_w, 1 q_w, Done. (0.058s)\n",
            "image 37/61 /content/drive/MyDrive/APS360_Project_Group_3/dataset/annotated/test_annotated/1b1K4-8-2R2B2-3qk2n-8-1B6-R4P2-4Q3.jpeg: 640x640 1 b_b, 5 b_ws, 2 r_ws, 1 n_b, 1 q_b, 2 q_ws, Done. (0.056s)\n",
            "image 38/61 /content/drive/MyDrive/APS360_Project_Group_3/dataset/annotated/test_annotated/1b1K4-R5k1-4r2N-8-8-8-8-Q7.jpeg: 640x640 3 b_bs, 3 r_bs, 1 r_w, 2 n_ws, 1 q_w, Done. (0.055s)\n",
            "image 39/61 /content/drive/MyDrive/APS360_Project_Group_3/dataset/annotated/test_annotated/1b1KN3-7B-2R5-4kr1r-1Q6-2Q1pr2-2B5-4n3.jpeg: 640x640 1 p_b, 1 b_b, 3 b_ws, 3 r_bs, 1 r_w, 1 n_b, 1 n_w, 1 k_b, 3 q_ws, Done. (0.057s)\n",
            "image 40/61 /content/drive/MyDrive/APS360_Project_Group_3/dataset/annotated/test_annotated/1b1Kq3-P3p3-2pnQ3-2b5-8-r4p2-3p4-3B3k.jpeg: 640x640 4 p_bs, 1 p_w, 3 b_bs, 3 b_ws, 1 r_b, 5 n_bs, 3 k_bs, 3 k_ws, 1 q_b, 1 q_w, Done. (0.055s)\n",
            "image 41/61 /content/drive/MyDrive/APS360_Project_Group_3/dataset/annotated/test_annotated/1b1N4-3K4-8-8-1N6-2r1r2k-8-8.jpeg: 640x640 1 b_b, 2 r_bs, 2 n_ws, 1 k_b, 1 k_w, Done. (0.055s)\n",
            "image 42/61 /content/drive/MyDrive/APS360_Project_Group_3/dataset/annotated/test_annotated/1b1N4-5K1k-3p4-3r2b1-1n6-8-3r1n2-2QQ4.jpeg: 640x640 1 p_b, 3 b_bs, 4 n_bs, 2 n_ws, 1 k_b, 1 k_w, 2 q_bs, 1 q_w, Done. (0.058s)\n",
            "image 43/61 /content/drive/MyDrive/APS360_Project_Group_3/dataset/annotated/test_annotated/1b1N4-7k-4b3-8-8-8-3P4-3K4.jpeg: 640x640 1 p_w, 3 b_bs, 2 n_ws, 2 k_bs, 1 k_w, Done. (0.055s)\n",
            "image 44/61 /content/drive/MyDrive/APS360_Project_Group_3/dataset/annotated/test_annotated/1b1N4-8-2K5-1nr2p2-Nn6-1RQ5-8-R5rk.jpeg: 640x640 1 p_b, 1 b_b, 1 b_w, 2 r_bs, 2 r_ws, 2 n_bs, 1 n_w, 1 k_b, 1 k_w, 1 q_w, Done. (0.056s)\n",
            "image 45/61 /content/drive/MyDrive/APS360_Project_Group_3/dataset/annotated/test_annotated/1b1N4-8-8-2N1N3-P7-p7-4r1k1-3K4.jpeg: 640x640 2 p_bs, 4 b_bs, 1 r_b, 3 n_ws, 2 k_bs, 1 k_w, Done. (0.054s)\n",
            "image 46/61 /content/drive/MyDrive/APS360_Project_Group_3/dataset/annotated/test_annotated/1b1N4-8-8-7k-3K1Pp1-8-8-3B4.jpeg: 640x640 1 p_b, 1 p_w, 3 b_bs, 2 b_ws, 2 n_bs, 2 n_ws, 1 k_b, 1 k_w, 1 q_w, Done. (0.057s)\n",
            "image 47/61 /content/drive/MyDrive/APS360_Project_Group_3/dataset/annotated/test_annotated/1b1NN3-3N3p-3k4-8-1K4b1-2R5-5r2-5N1B.jpeg: 640x640 1 p_b, 3 b_bs, 1 b_w, 2 r_bs, 1 r_w, 3 n_bs, 2 n_ws, 1 k_b, 1 k_w, Done. (0.055s)\n",
            "image 48/61 /content/drive/MyDrive/APS360_Project_Group_3/dataset/annotated/test_annotated/1b1Q1B1R-8-r7-K2n4-q7-1P2k2N-8-BQ2N3.jpeg: 640x640 1 p_w, 2 b_bs, 4 b_ws, 1 r_b, 1 r_w, 2 n_bs, 2 n_ws, 2 k_bs, 1 k_w, 1 q_b, 2 q_ws, Done. (0.056s)\n",
            "image 49/61 /content/drive/MyDrive/APS360_Project_Group_3/dataset/annotated/test_annotated/1b1Q4-3K1NP1-B7-8-R4N2-3r4-4q3-1N1k4.jpeg: 640x640 1 b_b, 2 b_ws, 1 r_b, 1 r_w, 3 n_ws, 1 k_b, 1 q_b, 1 q_w, Done. (0.056s)\n",
            "image 50/61 /content/drive/MyDrive/APS360_Project_Group_3/dataset/annotated/test_annotated/1b1b4-1N5r-1P1p3B-8-3KP3-3P2k1-3PB3-1N6.jpeg: 640x640 1 p_b, 4 p_ws, 2 b_bs, 2 b_ws, 1 r_b, 1 n_b, 4 n_ws, 2 k_bs, 1 k_w, Done. (0.056s)\n",
            "image 51/61 /content/drive/MyDrive/APS360_Project_Group_3/dataset/annotated/test_annotated/1b1b4-3q4-n6k-3b3R-Q7-1K3p2-1n6-1N3QRb.jpeg: 640x640 1 p_b, 6 b_bs, 2 b_ws, 2 r_ws, 3 n_bs, 2 n_ws, 1 k_b, 1 k_w, 3 q_bs, 2 q_ws, Done. (0.056s)\n",
            "image 52/61 /content/drive/MyDrive/APS360_Project_Group_3/dataset/annotated/test_annotated/1b1b4-Kn6-2Pk4-8-5p2-7n-7n-8.jpeg: 640x640 1 p_b, 2 b_bs, 1 b_w, 4 n_bs, 1 k_b, Done. (0.054s)\n",
            "image 53/61 /content/drive/MyDrive/APS360_Project_Group_3/dataset/annotated/test_annotated/1b1bB3-8-1P4k1-8-8-2K3r1-8-5bQ1.jpeg: 640x640 1 p_w, 4 b_bs, 1 b_w, 1 r_b, 1 k_b, 1 q_w, Done. (0.057s)\n",
            "image 54/61 /content/drive/MyDrive/APS360_Project_Group_3/dataset/annotated/test_annotated/1b1bK3-8-8-7r-1p5B-r4NkQ-8-6N1.jpeg: 640x640 2 b_bs, 3 b_ws, 1 r_b, 2 n_ws, 2 k_bs, 2 q_ws, Done. (0.054s)\n",
            "image 55/61 /content/drive/MyDrive/APS360_Project_Group_3/dataset/annotated/test_annotated/1b1k3N-8-5P2-N2p2N1-8-1Q6-3N4-K1Q3r1.jpeg: 640x640 1 p_b, 1 b_b, 1 r_b, 2 n_bs, 8 n_ws, 1 k_b, 1 k_w, 2 q_ws, Done. (0.055s)\n",
            "image 56/61 /content/drive/MyDrive/APS360_Project_Group_3/dataset/annotated/test_annotated/1b1n2B1-3K3N-7N-8-3pB3-P2N4-1Qrk4-n4n2.jpeg: 640x640 1 p_b, 3 b_bs, 3 b_ws, 4 n_bs, 3 n_ws, 2 k_bs, 2 k_ws, 1 q_b, Done. (0.055s)\n",
            "image 57/61 /content/drive/MyDrive/APS360_Project_Group_3/dataset/annotated/test_annotated/1b1n4-3q4-6n1-8-5K2-3Q4-8-1r5k.jpeg: 640x640 1 b_b, 1 r_b, 2 n_bs, 1 k_b, 1 k_w, 1 q_b, 1 q_w, Done. (0.055s)\n",
            "image 58/61 /content/drive/MyDrive/APS360_Project_Group_3/dataset/annotated/test_annotated/1b1n4-4BKP1-8-1r5n-3p1k2-3p4-3P4-6r1.jpeg: 640x640 2 p_bs, 2 p_ws, 1 b_b, 1 b_w, 2 r_bs, 4 n_bs, 3 k_bs, 1 k_w, Done. (0.057s)\n",
            "image 59/61 /content/drive/MyDrive/APS360_Project_Group_3/dataset/annotated/test_annotated/1b1n4-N7-7R-8-2K1p1p1-N3b3-B1p2PP1-3k4.jpeg: 640x640 3 p_bs, 2 p_ws, 5 b_bs, 5 b_ws, 1 r_w, 3 n_bs, 2 n_ws, 1 k_b, 1 k_w, Done. (0.056s)\n",
            "image 60/61 /content/drive/MyDrive/APS360_Project_Group_3/dataset/annotated/test_annotated/1b1nr3-p3N3-Bp6-1q6-2K1k3-B7-1P6-N7.jpeg: 640x640 2 p_bs, 1 p_w, 1 b_b, 2 b_ws, 1 r_b, 1 n_b, 4 n_ws, 1 k_b, 1 k_w, 2 q_bs, Done. (0.056s)\n",
            "image 61/61 /content/drive/MyDrive/APS360_Project_Group_3/dataset/annotated/test_annotated/1b1qb3-4r3-5k2-8-8-2R5-8-2K5.jpeg: 640x640 3 b_bs, 2 r_bs, 2 r_ws, 2 k_bs, Done. (0.055s)\n",
            "Results saved to \u001b[1m/content/drive/MyDrive/APS360_Project_Group_3/test_results/exp6\u001b[0m\n",
            "61 labels saved to /content/drive/MyDrive/APS360_Project_Group_3/test_results/exp6/labels\n",
            "Done. (10.458s)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f2OhZt2UEsEp",
        "outputId": "0cee5bc5-2862-426a-efbc-78fb40127480"
      },
      "source": [
        "!python detect.py --weights /content/drive/MyDrive/APS360_Project_Group_3/YOLOv5/yolov5x_b15_ep100_run_train282_val61/weights/best.pt \\\n",
        "  --img 200 --iou-thres 0.5 --conf 0.3 --line-thickness 1 --save-txt --save-conf --save-crop \\\n",
        "  --source /content/drive/MyDrive/APS360_Project_Group_3/dataset/annotated/test_annotated/1B1K4-3N1k1P-6Q1-3r1n2-8-3p1NNN-8-3b2rR.jpeg \\\n",
        "  --project /content/drive/MyDrive/APS360_Project_Group_3/test_results/1B1K4-3N1k1P-6Q1-3r1n2-8-3p1NNN-8-3b2rR.jpeg\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/content/drive/MyDrive/APS360_Project_Group_3/YOLOv5/yolov5x_b15_ep100_run_train282_val61/weights/best.pt'], source=/content/drive/MyDrive/APS360_Project_Group_3/dataset/annotated/test_annotated/1B1K4-3N1k1P-6Q1-3r1n2-8-3p1NNN-8-3b2rR.jpeg, imgsz=200, conf_thres=0.3, iou_thres=0.5, max_det=1000, device=, view_img=False, save_txt=True, save_conf=True, save_crop=True, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=/content/drive/MyDrive/APS360_Project_Group_3/test_results/1B1K4-3N1k1P-6Q1-3r1n2-8-3p1NNN-8-3b2rR.jpeg, name=exp, exist_ok=False, line_thickness=1, hide_labels=False, hide_conf=False, half=False\n",
            "YOLOv5 🚀 v5.0-351-ge96c74b torch 1.9.0+cu102 CUDA:0 (Tesla K80, 11441.1875MB)\n",
            "\n",
            "Fusing layers... \n",
            "Model Summary: 476 layers, 87272713 parameters, 0 gradients, 217.3 GFLOPs\n",
            "WARNING: --img-size 200 must be multiple of max stride 32, updating to 224\n",
            "image 1/1 /content/drive/MyDrive/APS360_Project_Group_3/dataset/annotated/test_annotated/1B1K4-3N1k1P-6Q1-3r1n2-8-3p1NNN-8-3b2rR.jpeg: 224x224 1 p_b, 1 p_w, 1 b_b, 1 b_w, 2 r_bs, 1 r_w, 1 n_b, 4 n_ws, 1 k_b, 1 k_w, 1 q_w, Done. (0.082s)\n",
            "Results saved to \u001b[1m/content/drive/MyDrive/APS360_Project_Group_3/test_results/1B1K4-3N1k1P-6Q1-3r1n2-8-3p1NNN-8-3b2rR.jpeg/exp\u001b[0m\n",
            "1 labels saved to /content/drive/MyDrive/APS360_Project_Group_3/test_results/1B1K4-3N1k1P-6Q1-3r1n2-8-3p1NNN-8-3b2rR.jpeg/exp/labels\n",
            "Done. (1.355s)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xmjXXwA2HYSq"
      },
      "source": [
        "\n",
        "!python train.py --img 200 --batch 50 --epochs 200 \\\n",
        "  --data /content/yolov5/FEN.yaml --weights yolov5x.pt \\\n",
        "  --name yolov5x_b50_ep200_run_train282_val61 --cache --project /content/drive/MyDrive/APS360_Project_Group_3/YOLOv5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MaKMR2Y4gJmX",
        "outputId": "6f59f080-ae06-4c18-b7c7-b482fba36f51"
      },
      "source": [
        "# trying to use val.py\n",
        "!python val.py --weights /content/drive/MyDrive/APS360_Project_Group_3/YOLOv5/yolov5x_b15_ep100_run_train282_val61/weights/best.pt \\\n",
        "  --img 200 --task test --data /content/yolov5/FEN.yaml \\\n",
        "  --save-txt --save-conf --iou-thres 0.5 --conf-thres 0.9 \\\n",
        "  --project /content/drive/MyDrive/APS360_Project_Group_3/test_results/conf_90"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mdata=/content/yolov5/FEN.yaml, weights=['/content/drive/MyDrive/APS360_Project_Group_3/YOLOv5/yolov5x_b15_ep100_run_train282_val61/weights/best.pt'], batch_size=32, imgsz=200, conf_thres=0.9, iou_thres=0.5, task=test, device=, single_cls=False, augment=False, verbose=False, save_txt=True, save_hybrid=False, save_conf=True, save_json=False, project=/content/drive/MyDrive/APS360_Project_Group_3/test_results/conf_90, name=exp, exist_ok=False, half=False\n",
            "YOLOv5 🚀 v5.0-351-ge96c74b torch 1.9.0+cu102 CUDA:0 (Tesla T4, 15109.75MB)\n",
            "\n",
            "Fusing layers... \n",
            "Model Summary: 476 layers, 87272713 parameters, 0 gradients, 217.3 GFLOPs\n",
            "WARNING: --img-size 200 must be multiple of max stride 32, updating to 224\n",
            "\u001b[34m\u001b[1mtest: \u001b[0mScanning '/content/drive/MyDrive/APS360_Project_Group_3/dataset/annotated/test_annotated.cache' images and labels... 61 found, 0 missing, 0 empty, 0 corrupted: 100% 61/61 [00:00<00:00, 582807.62it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 2/2 [00:01<00:00,  1.89it/s]\n",
            "                 all         61          0          0          0          0          0\n",
            "Speed: 0.0ms pre-process, 11.9ms inference, 0.3ms NMS per image at shape (32, 3, 224, 224)\n",
            "Results saved to \u001b[1m/content/drive/MyDrive/APS360_Project_Group_3/test_results/conf_90/exp\u001b[0m\n",
            "0 labels saved to /content/drive/MyDrive/APS360_Project_Group_3/test_results/conf_90/exp/labels\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WJZBY4-x3k4C"
      },
      "source": [
        "## Testing Completely New Data from Google Images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "se7UQduR3vAc"
      },
      "source": [
        "Steps to test new images on our trained model:\n",
        "1. Find image you want to convert into FEN notation (make sure it is a screenshot of only the chess board with chess pieces on it for best results)\n",
        "2. Save it onto Google Drive (remember where you saved it! You will need the path to the image)\n",
        "3. Change the --source to the image path from Step 2\n",
        "4. Make sure you are using the best model (in our case, the best model is called yolov5x_b15_ep100_run_train282_val61/weights/best.pt)\n",
        "  - best.pt saves the best run out of the 100 epochs we ran our model through\n",
        "5. Use --project to specify where you want the model to output the result (will output the image inputted with it's bounding box and class predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qLRIMytp-arq",
        "outputId": "5168bf4b-dc43-4821-f0c9-970efdbba00a"
      },
      "source": [
        "# testing a random images from google\n",
        "!python detect.py --weights /content/drive/MyDrive/APS360_Project_Group_3/YOLOv5/yolov5x_b15_ep100_run_train282_val61/weights/best.pt \\\n",
        "  --img 200 --iou-thres 0.5 --conf 0.5 --line-thickness 1 --save-txt --save-conf --save-crop \\\n",
        "  --source /content/drive/MyDrive/APS360_Project_Group_3/dataset/random_chess_screenshots/aps2.png \\\n",
        "  --project /content/drive/MyDrive/APS360_Project_Group_3/test_results/random_screenshot/aps2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/content/drive/MyDrive/APS360_Project_Group_3/YOLOv5/yolov5x_b15_ep100_run_train282_val61/weights/best.pt'], source=/content/drive/MyDrive/APS360_Project_Group_3/dataset/random_chess_screenshots/aps2.png, imgsz=200, conf_thres=0.5, iou_thres=0.5, max_det=1000, device=, view_img=False, save_txt=True, save_conf=True, save_crop=True, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=/content/drive/MyDrive/APS360_Project_Group_3/test_results/random_screenshot/aps2, name=exp, exist_ok=False, line_thickness=1, hide_labels=False, hide_conf=False, half=False\n",
            "YOLOv5 🚀 v5.0-351-ge96c74b torch 1.9.0+cu102 CUDA:0 (Tesla T4, 15109.75MB)\n",
            "\n",
            "Fusing layers... \n",
            "Model Summary: 476 layers, 87272713 parameters, 0 gradients, 217.3 GFLOPs\n",
            "WARNING: --img-size 200 must be multiple of max stride 32, updating to 224\n",
            "image 1/1 /content/drive/MyDrive/APS360_Project_Group_3/dataset/random_chess_screenshots/aps2.png: 224x224 7 p_bs, 7 p_ws, 1 b_b, 1 b_w, 2 r_bs, 2 r_ws, 1 n_b, 1 n_w, 1 k_b, 1 k_w, 1 q_b, 1 q_w, Done. (0.029s)\n",
            "Results saved to \u001b[1m/content/drive/MyDrive/APS360_Project_Group_3/test_results/random_screenshot/aps2/exp\u001b[0m\n",
            "1 labels saved to /content/drive/MyDrive/APS360_Project_Group_3/test_results/random_screenshot/aps2/exp/labels\n",
            "Done. (1.087s)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JDUyXzzVEMRZ"
      },
      "source": [
        "# Extracting bounding box position of prediction to convert to FEN\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4J-sIVVQ5NIE"
      },
      "source": [
        "- We read the text file that the model outputs and extract the bounding box location of each object detected\n",
        "- We map each detected object to it's corresponding piece and position on the board\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sqLrkiqzllMs"
      },
      "source": [
        "def pieceAndName(string):\n",
        "  if(string == \"Rook\"):\n",
        "    return \"R\"\n",
        "  elif(string == \"Queen\"):\n",
        "    return \"Q\"\n",
        "  elif(string == \"Pawn\"):\n",
        "    return \"P\"\n",
        "  elif(string == \"Knight\"):\n",
        "    return \"N\"\n",
        "  elif(string == \"King\"):\n",
        "    return \"K\"\n",
        "  elif(string == \"Bishop\"):\n",
        "    return \"B\"\n",
        "  elif(string == \"rook\"):\n",
        "    return \"r\"\n",
        "  elif(string == \"queen\"):\n",
        "    return \"q\"\n",
        "  elif(string == \"pawn\"):\n",
        "    return \"p\"\n",
        "  elif(string == \"knight\"):\n",
        "    return \"n\"\n",
        "  elif(string == \"king\"):\n",
        "    return \"k\"\n",
        "  elif(string == \"bishop\"):\n",
        "    return \"b\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6jjlCR-DCz_m"
      },
      "source": [
        "\n",
        "\n",
        "#print(\"piece + position on the board: \")\n",
        "def get_fen(f):\n",
        "  fen = {}\n",
        "  for x in f:\n",
        "    ind = x.split()\n",
        "    v_axis = 224*float(ind[1])\n",
        "    h_axis = 224*float(ind[2])\n",
        "    sep = 224/8\n",
        "    piece=''\n",
        "    p1=''\n",
        "    p2=''\n",
        "    if ind[0]=='0':\n",
        "      piece='pawn'\n",
        "    elif ind[0]=='1':\n",
        "      piece='Pawn'\n",
        "    elif ind[0]=='2':\n",
        "      piece='bishop'\n",
        "    elif ind[0]=='3':\n",
        "      piece='Bishop'\n",
        "    elif ind[0]=='4':\n",
        "      piece='rook'\n",
        "    elif ind[0]=='5':\n",
        "      piece='Rook'\n",
        "    elif ind[0]=='6':\n",
        "      piece='knight'\n",
        "    elif ind[0]=='7':\n",
        "      piece='Knight'\n",
        "    elif ind[0]=='8':\n",
        "      piece='king'\n",
        "    elif ind[0]=='9':\n",
        "      piece='King'\n",
        "    elif ind[0]=='10':\n",
        "      piece='queen'\n",
        "    elif ind[0]=='11':\n",
        "      piece='Queen'\n",
        "    if v_axis >0 and v_axis<=sep:\n",
        "      p1='A'\n",
        "    if v_axis >sep and v_axis<=2*sep:\n",
        "      p1='B'\n",
        "    if v_axis >2*sep and v_axis<=3*sep:\n",
        "      p1='C'\n",
        "    if v_axis >3*sep and v_axis<=4*sep:\n",
        "      p1='D'\n",
        "    if v_axis >4*sep and v_axis<=5*sep:\n",
        "      p1='E'\n",
        "    if v_axis >5*sep and v_axis<=6*sep:\n",
        "      p1='F'\n",
        "    if v_axis >6*sep and v_axis<=7*sep:\n",
        "      p1='G'\n",
        "    if v_axis >7*sep and v_axis<=8*sep:\n",
        "      p1='H'\n",
        "\n",
        "    if h_axis >0 and h_axis<=sep:\n",
        "      p2='8'\n",
        "    if h_axis >sep and h_axis<=2*sep:\n",
        "      p2='7'\n",
        "    if h_axis >2*sep and h_axis<=3*sep:\n",
        "      p2='6'\n",
        "    if h_axis >3*sep and h_axis<=4*sep:\n",
        "      p2='5'\n",
        "    if h_axis >4*sep and h_axis<=5*sep:\n",
        "      p2='4'\n",
        "    if h_axis >5*sep and h_axis<=6*sep:\n",
        "      p2='3'\n",
        "    if h_axis >6*sep and h_axis<=7*sep:\n",
        "      p2='2'\n",
        "    if h_axis >7*sep and h_axis<=8*sep:\n",
        "      p2='1'\n",
        "    fen.setdefault(p2, []).append(piece)\n",
        "    fen.setdefault(p2, []).append(p1)\n",
        "    \n",
        "    \n",
        "    #print('{} --> {}{}'.format(piece,p1,p2))\n",
        "\n",
        "\n",
        "  c=8\n",
        "  output=''\n",
        "  for x in range(8):\n",
        "    y=c-x\n",
        "    count =0\n",
        "    if str(y) in fen:\n",
        "      if'A' in fen.setdefault(str(y), {}):\n",
        "        output += pieceAndName(fen.setdefault(str(y), {})[fen.setdefault(str(y), {}).index('A')-1])\n",
        "        count = 1\n",
        "      if'B' in fen.setdefault(str(y), {}):\n",
        "        if count== 0: \n",
        "          output += '1'\n",
        "          output += pieceAndName(fen.setdefault(str(y), {})[fen.setdefault(str(y), {}).index('B')-1])\n",
        "        if count== 1:\n",
        "          output += pieceAndName(fen.setdefault(str(y), {})[fen.setdefault(str(y), {}).index('B')-1])\n",
        "        count =2\n",
        "      if'C' in fen.setdefault(str(y), {}):\n",
        "        if count ==0:\n",
        "          output += '2'\n",
        "          output += pieceAndName(fen.setdefault(str(y), {})[fen.setdefault(str(y), {}).index('C')-1])\n",
        "        if count == 1:\n",
        "          output += '1'\n",
        "          output += pieceAndName(fen.setdefault(str(y), {})[fen.setdefault(str(y), {}).index('C')-1])\n",
        "        if count ==2:\n",
        "          output += pieceAndName(fen.setdefault(str(y), {})[fen.setdefault(str(y), {}).index('C')-1])\n",
        "        count = 3\n",
        "      if'D' in fen.setdefault(str(y), {}):\n",
        "        if count ==0:\n",
        "          output += '3'\n",
        "          output += pieceAndName(fen.setdefault(str(y), {})[fen.setdefault(str(y), {}).index('D')-1])\n",
        "        if count == 1:\n",
        "          output += '2'\n",
        "          output += pieceAndName(fen.setdefault(str(y), {})[fen.setdefault(str(y), {}).index('D')-1])\n",
        "        if count ==2:\n",
        "          output += '1'\n",
        "          output += pieceAndName(fen.setdefault(str(y), {})[fen.setdefault(str(y), {}).index('D')-1])\n",
        "        if count ==3:\n",
        "          output += pieceAndName(fen.setdefault(str(y), {})[fen.setdefault(str(y), {}).index('D')-1])\n",
        "        count = 4\n",
        "      if 'E' in fen.setdefault(str(y), {}):\n",
        "        if count ==0:\n",
        "          output += '4'\n",
        "          output += pieceAndName(fen.setdefault(str(y), {})[fen.setdefault(str(y), {}).index('E')-1])\n",
        "        if count == 1:\n",
        "          output += '3'\n",
        "          output += pieceAndName(fen.setdefault(str(y), {})[fen.setdefault(str(y), {}).index('E')-1])\n",
        "        if count ==2:\n",
        "          output += '2'\n",
        "          output += pieceAndName(fen.setdefault(str(y), {})[fen.setdefault(str(y), {}).index('E')-1])\n",
        "        if count ==3:\n",
        "          output += '1'\n",
        "          output += pieceAndName(fen.setdefault(str(y), {})[fen.setdefault(str(y), {}).index('E')-1])\n",
        "        if count ==4:\n",
        "          output += pieceAndName(fen.setdefault(str(y), {})[fen.setdefault(str(y), {}).index('E')-1])\n",
        "        count = 5\n",
        "      if'F' in fen.setdefault(str(y), {}):\n",
        "        if count ==0:\n",
        "          output += '5'\n",
        "          output += pieceAndName(fen.setdefault(str(y), {})[fen.setdefault(str(y), {}).index('F')-1])\n",
        "        if count == 1:\n",
        "          output += '4'\n",
        "          output += pieceAndName(fen.setdefault(str(y), {})[fen.setdefault(str(y), {}).index('F')-1])\n",
        "        if count ==2:\n",
        "          output += '3'\n",
        "          output += pieceAndName(fen.setdefault(str(y), {})[fen.setdefault(str(y), {}).index('F')-1])\n",
        "        if count ==3:\n",
        "          output += '2'\n",
        "          output += pieceAndName(fen.setdefault(str(y), {})[fen.setdefault(str(y), {}).index('F')-1])\n",
        "        if count ==4:\n",
        "          output+= '1'\n",
        "          output += pieceAndName(fen.setdefault(str(y), {})[fen.setdefault(str(y), {}).index('F')-1])\n",
        "        if count ==5:\n",
        "          output += pieceAndName(fen.setdefault(str(y), {})[fen.setdefault(str(y), {}).index('F')-1])\n",
        "        count = 6\n",
        "      if'G' in fen.setdefault(str(y), {}):\n",
        "        if count ==0:\n",
        "          output += '6'\n",
        "          output += pieceAndName(fen.setdefault(str(y), {})[fen.setdefault(str(y), {}).index('G')-1])\n",
        "        if count == 1:\n",
        "          output += '5'\n",
        "          output += pieceAndName(fen.setdefault(str(y), {})[fen.setdefault(str(y), {}).index('G')-1])\n",
        "        if count ==2:\n",
        "          output += '4'\n",
        "          output += pieceAndName(fen.setdefault(str(y), {})[fen.setdefault(str(y), {}).index('G')-1])\n",
        "        if count ==3:\n",
        "          output += '3'\n",
        "          output += pieceAndName(fen.setdefault(str(y), {})[fen.setdefault(str(y), {}).index('G')-1])\n",
        "        if count ==4:\n",
        "          output+= '2'\n",
        "          output += pieceAndName(fen.setdefault(str(y), {})[fen.setdefault(str(y), {}).index('G')-1])\n",
        "        if count ==5:\n",
        "          output+= '1'\n",
        "          output += pieceAndName(fen.setdefault(str(y), {})[fen.setdefault(str(y), {}).index('G')-1])\n",
        "        if count ==6:\n",
        "          output += pieceAndName(fen.setdefault(str(y), {})[fen.setdefault(str(y), {}).index('G')-1])\n",
        "        count = 7\n",
        "      if'H' in fen.setdefault(str(y), {}):\n",
        "        if count ==0:\n",
        "          output += '7'\n",
        "          output += pieceAndName(fen.setdefault(str(y), {})[fen.setdefault(str(y), {}).index('H')-1])\n",
        "        if count == 1:\n",
        "          output += '6'\n",
        "          output += pieceAndName(fen.setdefault(str(y), {})[fen.setdefault(str(y), {}).index('H')-1])\n",
        "        if count ==2:\n",
        "          output += '5'\n",
        "          output += pieceAndName(fen.setdefault(str(y), {})[fen.setdefault(str(y), {}).index('H')-1])\n",
        "        if count ==3:\n",
        "          output += '4'\n",
        "          output += pieceAndName(fen.setdefault(str(y), {})[fen.setdefault(str(y), {}).index('H')-1])\n",
        "        if count ==4:\n",
        "          output+= '3'\n",
        "          output += pieceAndName(fen.setdefault(str(y), {})[fen.setdefault(str(y), {}).index('H')-1])\n",
        "        if count ==5:\n",
        "          output+= '2'\n",
        "          output += pieceAndName(fen.setdefault(str(y), {})[fen.setdefault(str(y), {}).index('H')-1])\n",
        "        if count ==6:\n",
        "          output+= '1'\n",
        "          output += pieceAndName(fen.setdefault(str(y), {})[fen.setdefault(str(y), {}).index('H')-1])\n",
        "        if count ==7:\n",
        "          output += pieceAndName(fen.setdefault(str(y), {})[fen.setdefault(str(y), {}).index('H')-1])\n",
        "        count =8\n",
        "      if count ==7:\n",
        "        output+= '1'\n",
        "      if count ==6:\n",
        "        output+= '2'\n",
        "      if count ==5:\n",
        "        output+= '3'\n",
        "      if count ==4:\n",
        "        output+= '4'\n",
        "      if count ==3:\n",
        "        output+= '5'\n",
        "      if count ==2:\n",
        "        output+= '6'\n",
        "      if count ==1:\n",
        "        output+= '7'\n",
        "    else:\n",
        "      output+= '8'\n",
        "    output+= '-'\n",
        "  return output[:-1]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b0Q_RuAx5mdg"
      },
      "source": [
        "### Computing the accuracy of our model predicition to FEN notation conversion"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ciucos7FuJKL",
        "outputId": "5bca3333-8686-4e59-a8bb-fae214235caa"
      },
      "source": [
        "import os\n",
        "path = '/content/drive/MyDrive/APS360_Project_Group_3/test_results/conf_50/exp/labels'\n",
        "correct = 0\n",
        "total = 0\n",
        "for i in os.listdir(path):\n",
        " \n",
        "  ground = i[:-4]\n",
        "  \n",
        "  f = open(os.path.join(path, i), \"r\")\n",
        "  test = get_fen(f)\n",
        "\n",
        "  if test==ground:\n",
        "    correct +=1\n",
        "  else:\n",
        "    print (test)\n",
        "    print (ground)\n",
        "  total += 1\n",
        "  \n",
        "\n",
        "print (\"The fen accuracy is : \" + str (correct/total))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1b1K4-R5k1-4r2N-8-8-8-8-K7\n",
            "1b1K4-R5k1-4r2N-8-8-8-8-Q7\n",
            "1b1NN3-3N3p-3K4-8-1K4b1-2R5-5r2-5N1B\n",
            "1b1NN3-3N3p-3k4-8-1K4b1-2R5-5r2-5N1B\n",
            "1B1b4-3q4-n6k-3b3R-Q7-1K3p2-1n6-1N3QRb\n",
            "1b1b4-3q4-n6k-3b3R-Q7-1K3p2-1n6-1N3QRb\n",
            "1B1B4-4r3-2r2p2-K7-8-3b3r-2Q4P-R2k4\n",
            "1B1B4-4R3-2R2p2-K7-8-3b3r-2Q4P-R2k4\n",
            "1B1K4-1p5N-7p-1qp5-n1P5-8-6k1-B7\n",
            "1B1K4-1p5N-7p-1qp5-n1P5-8-6k1-b7\n",
            "1B1n4-2p1b3-p1K1PBr1-2b4k-6B1-8-8-BN6\n",
            "1B1n4-2p1b3-P1K1PBR1-2b4k-6B1-8-8-BN6\n",
            "The fen accuracy is : 0.9016393442622951\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Uz0IpdH5xWE"
      },
      "source": [
        "### Get Final Output in FEN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eg42OrKmN1JU",
        "outputId": "21fd41ef-85a6-4180-c835-180ddaf96474"
      },
      "source": [
        "i= \"/content/drive/MyDrive/APS360_Project_Group_3/test_results/random_screenshot/aps2/exp/labels/aps2.txt\"\n",
        "f = open(i, \"r\")\n",
        "print (get_fen(f).replace(\"-\",\"/\"))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3r1rk1/1pR1bpp1/3p3p/pP2p3/P3Pnq1/BP1Q1NP1/5P1P/3R2K1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iX5EixoVSwK3"
      },
      "source": [
        "# Testing model with Random Screenshots\n",
        "- Taking output from model, reading the text file, then converting directly to FEN using the get_fen() function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rtpXIRxDS1Jd",
        "outputId": "34ca00f7-acb4-481f-919f-889082d17d31"
      },
      "source": [
        "i= \"/content/drive/MyDrive/APS360_Project_Group_3/test_results/random_screenshot/wikihow-Win-Chess-Openings_-Playing-Black-Step-14.jpg/exp/labels/wikihow-Win-Chess-Openings_-Playing-Black-Step-14.txt\"\n",
        "f = open(i, \"r\")\n",
        "print (get_fen(f).replace(\"-\",\"/\"))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1nkpbb2/1K1k1kk1/4K3/2BN4/1KKK1K2/1KNKKKK1/1PNNKNP1/8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XknH-ZFsVxPz",
        "outputId": "4043e9ba-fe58-40f5-e584-5004e3cc9350"
      },
      "source": [
        "i= \"/content/drive/MyDrive/APS360_Project_Group_3/test_results/random_screenshot/basic-principles-of-chess-openings-611601-control-the-center.png/exp/labels/basic-principles-of-chess-openings-611601-control-the-center.txt\"\n",
        "f = open(i, \"r\")\n",
        "print (get_fen(f).replace(\"-\",\"/\"))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "r1bkkb1r/1pppppp1/n6n/p6p/3RP3/2N2N2/PPR2PRP/R1BQKB1R\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}