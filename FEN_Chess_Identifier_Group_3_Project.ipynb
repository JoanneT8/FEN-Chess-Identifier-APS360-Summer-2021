{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FEN Chess Identifier - Group 3 Project",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JoanneT8/FEN-Chess-Identifier-APS360-Summer-2021/blob/main/FEN_Chess_Identifier_Group_3_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-oQfyXToPntL"
      },
      "source": [
        "## FEN Chess Identifier Project"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7vAEqXKsPO8j"
      },
      "source": [
        "Welcome to Group 3's Google Colab Notebook! This is where we are going to build our FEN Chess Identifier machine learning model for APS360 Summer 2021.\n",
        "\n",
        "**Team members: John Lee, Kevin Karam, Morgan Tran, Joanne Tan**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hxb2jIn37lUh"
      },
      "source": [
        "##  Project Overview\n",
        "[Why did we choose this? What kind of results do we want?]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JjilcK1j7tzB"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3xFs6COgPx2E"
      },
      "source": [
        "## Google Colab Shared Link\n",
        "Link: https://colab.research.google.com/drive/1hBLG7VLoNU6S6vvo8Ff9rpU0ix5F1Wwj?usp=sharing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XnHedjPPQDRf"
      },
      "source": [
        "## Git Repository\n",
        "Current Git repo is still private."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aeeSSsUacGVh"
      },
      "source": [
        "# Clean the Data\n",
        "- Download the dataset\n",
        "- Resize all images to 200 x 200 pixels\n",
        "- Extract JPG name and replace all dashes with slashes, store into a dataframe?\n",
        "- Convert images into numpy arrays, store into csv file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fonNdl1Pcdhi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6fe5fb2d-5cf4-446f-b161-e09dc8d8676d"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RHgiw7A4qCCh"
      },
      "source": [
        "### Resizing images to 200 x 200 px"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3TxOKWFmgbef"
      },
      "source": [
        "Following steps to download Kaggle dataset from this article: https://towardsdatascience.com/downloading-datasets-into-google-drive-via-google-colab-bcb1b30b0166"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NY5OOGVSgZ2-"
      },
      "source": [
        "from google.colab import files\n",
        "files.upload()  #this will prompt you to upload the kaggle.json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yjQeccgthlDV"
      },
      "source": [
        "# make sure you have pip installed\n",
        "!pip --version "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eS0kbYaoilzl"
      },
      "source": [
        "!pip install -q kaggle\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!ls ~/.kaggle\n",
        "!chmod 600 /root/.kaggle/kaggle.json  # set permission"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OEP20ZqSeLey"
      },
      "source": [
        "# import the Kaggle dataset from: https://www.kaggle.com/koryakinp/chess-positions \n",
        "!kaggle datasets download -d koryakinp/chess-positions -p '/content/drive/MyDrive/APS360_Project_Group_3/Chess_Positions_Datset'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H2UK83DHnXTw"
      },
      "source": [
        "import os\n",
        "os.chdir('/content/drive/MyDrive/APS360_Project_Group_3')  #change dir"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x7lD2N0z-OBz"
      },
      "source": [
        "**Note: Beware, unzipping this file takes approx. 2 hours 21 min!!!!!**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IpcPMCm2xfwh"
      },
      "source": [
        "!unzip -q archive.zip  #unzip dataset "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f0FqJahW4tYt"
      },
      "source": [
        "# split a portion of the train data for a validation set\n",
        "# save 20k images for validation set, 60k for training\n",
        "\n",
        "#hmmm how do i split the train set in an easy way"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XQmVHO4QGkgP"
      },
      "source": [
        "import numpy as np\n",
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "import torchvision.transforms as transforms\n",
        "import os\n",
        "import shutil"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jer102ojGyrc"
      },
      "source": [
        "train_dir = '/content/drive/MyDrive/APS360_Project_Group_3/dataset/train'\n",
        "val_dir = '/content/drive/MyDrive/APS360_Project_Group_3/dataset/validation'\n",
        "test_dir = '/content/drive/MyDrive/APS360_Project_Group_3/dataset/test'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T1LpqakJQvI3"
      },
      "source": [
        "# why is this not working ughhhhhhh - it works on and off -- Reason: sometimes Google Colab finds the file to big to read \n",
        "# check to see if we have all the files\n",
        "counter_train = 0\n",
        "counter_val = 0\n",
        "counter_test = 0\n",
        "\n",
        "for file in os.listdir(train_dir):\n",
        "  # print(file)\n",
        "  counter_train += 1\n",
        "\n",
        "for file in os.listdir(val_dir):\n",
        "  counter_val += 1\n",
        "\n",
        "for file in os.listdir(test_dir):\n",
        "  counter_test += 1\n",
        "  \n",
        "print(counter_train)\n",
        "print(counter_val)\n",
        "print(counter_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5C5p2HauxtpI"
      },
      "source": [
        "# ------------- DON'T RUN AGAIN --------------\n",
        "# move 20,000 images into validation folder\n",
        "# counter = 0\n",
        "# for file in os.listdir(train_dir):\n",
        "#   curr_path = os.path.join(train_dir, file)\n",
        "#   if (counter < 20000):\n",
        "#     shutil.move(curr_path, val_dir)\n",
        "#     counter += 1\n",
        "#   else:\n",
        "#     break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FipplZuRtZKH"
      },
      "source": [
        "Resizing images to 200 x 200 pixels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oz6rW5bDrFAf"
      },
      "source": [
        "#Import required Image library\n",
        "from PIL import Image\n",
        "counter = 0\n",
        "finished = 0\n",
        "other = 0\n",
        "new_size = (200,200)\n",
        "\n",
        "# resizing all images in train folder\n",
        "for file in os.listdir(train_dir):\n",
        "  curr_path = os.path.join(train_dir, file)\n",
        "\n",
        "  #Create an Image Object from an Image\n",
        "  im = Image.open(curr_path)\n",
        "\n",
        "  # #Display actual image\n",
        "  # im.show()\n",
        "\n",
        "  if (im.size[0] != 200):\n",
        "    #Make the new image half the width and half the height of the original image\n",
        "    resized_im = im.resize(new_size)\n",
        "\n",
        "    # #Display the resized imaged\n",
        "    # resized_im.show()\n",
        "    print(file)\n",
        "    print(resized_im.size)\n",
        "    print(counter)\n",
        "    print()\n",
        "\n",
        "    counter += 1\n",
        "    #Save the cropped image\n",
        "    resized_im.save(curr_path)\n",
        "  elif (im.size[0] == 200):\n",
        "    print(\"complete: \" + str(finished))\n",
        "    finished += 1\n",
        "    print(im.size)\n",
        "  else:\n",
        "    print(\"other: \" + str(other))\n",
        "    other += 1\n",
        "    print(im.size)\n",
        "\n",
        "print()\n",
        "print()\n",
        "print(\"Completed = \" + str(finished))\n",
        "print(\"resized = \" + str(counter))\n",
        "print(\"other = \" + str(other))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TYym9CpXtL_i"
      },
      "source": [
        "counter = 0\n",
        "new_size = (200,200)\n",
        "\n",
        "# resizing all images in validation folder\n",
        "for file in os.listdir(val_dir):\n",
        "  curr_path = os.path.join(val_dir, file)\n",
        "\n",
        "  #Create an Image Object from an Image\n",
        "  im = Image.open(curr_path)\n",
        "\n",
        "  # #Display actual image\n",
        "  # im.show()\n",
        "\n",
        "  if (im.size[0] != 200):\n",
        "    #Make the new image half the width and half the height of the original image\n",
        "    resized_im = im.resize(new_size)\n",
        "\n",
        "    # #Display the resized imaged\n",
        "    # resized_im.show()\n",
        "    print(file)\n",
        "    print(resized_im.size)\n",
        "    print(counter)\n",
        "    print()\n",
        "\n",
        "    counter += 1\n",
        "    #Save the cropped image\n",
        "    resized_im.save(curr_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aDM9yCLHtR7j"
      },
      "source": [
        "counter = 0\n",
        "new_size = (200,200)\n",
        "\n",
        "# resizing all images in test folder\n",
        "for file in os.listdir(test_dir):\n",
        "  curr_path = os.path.join(test_dir, file)\n",
        "\n",
        "  #Create an Image Object from an Image\n",
        "  im = Image.open(curr_path)\n",
        "\n",
        "  # #Display actual image\n",
        "  # im.show()\n",
        "\n",
        "  if (im.size[0] != 200):\n",
        "    #Make the new image half the width and half the height of the original image\n",
        "    resized_im = im.resize(new_size)\n",
        "\n",
        "    # #Display the resized imaged\n",
        "    # resized_im.show()\n",
        "    print(file)\n",
        "    print(resized_im.size)\n",
        "    print(counter)\n",
        "    print()\n",
        "\n",
        "    counter += 1\n",
        "    #Save the cropped image\n",
        "    resized_im.save(curr_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GFndOlyC9DRL"
      },
      "source": [
        "Convert images into numpy array, and save to csv file along with the jpg modified name:\n",
        "https://www.geeksforgeeks.org/how-to-convert-an-image-to-numpy-array-and-saveit-to-csv-file-using-python/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xTcqKV1-9LyL"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xjejrF1-9MRE"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BueUUUFISaL7"
      },
      "source": [
        "## How to differentiate between pieces?\n",
        "- 13 classes (6 classes for white, 6 for black, 1 for blanks)\n",
        "Augmenting pieces:\n",
        "- change resolutions\n",
        "- edge detection?\n",
        "- mirror (if piece not symmetrical)\n",
        "- add blank images\n",
        "- add noise\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "re3xf3HvrzPZ"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BWAajcZTpNzC"
      },
      "source": [
        "# create folders\n",
        "#input 5 folders named, base, colour, noise, colournoise, mirror inside each of the 13 pieces"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LQslPvsMoh2K"
      },
      "source": [
        "# function for mirror\n",
        "\n",
        "from PIL import Image\n",
        "import os \n",
        "\n",
        "pieces_dataset_path = '/content/drive/MyDrive/APS360_Project_Group_3/pieces'\n",
        "\n",
        "for file in os.listdir(pieces_dataset_path):\n",
        "  im = Image.open(pieces_dataset_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mkZpURIuoiks"
      },
      "source": [
        "# function for noise"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XicsOjClokEs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        },
        "outputId": "2d8846a8-c031-4674-b893-bcca776fdf67"
      },
      "source": [
        "# function for background colour\n",
        "\n",
        "import os\n",
        "pieces_dataset_path = '/content/drive/MyDrive/APS360_Project_Group_3/pieces'\n",
        "\n",
        "dir_list = next(os.walk(pieces_dataset_path))[1]\n",
        "\n",
        "print(dir_list)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "StopIteration",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-068296e42b7e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mpieces_dataset_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/drive/MyDrive/APS360_Project_Group_3/pieces'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mdir_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwalk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpieces_dataset_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdir_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mStopIteration\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "laR96CB0ojq6"
      },
      "source": [
        "# function for converting png to jpeg ->joanne\n",
        "# https://stackoverflow.com/questions/43258461/convert-png-to-jpeg-using-pillow \n",
        "\n",
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "pieces_dataset_path = '/content/drive/MyDrive/APS360_Project_Group_3/pieces'\n",
        "\n",
        "\n",
        "\n",
        "for file in os.listdir(pieces_dataset_path):\n",
        "  curr_path = os.path.join(pieces_dataset_path, file)\n",
        "  fileName = os.path.splitext(curr_path)[0]\n",
        "  im = Image.open(curr_path)\n",
        "  rgb_im = im.convert('RGB')\n",
        "  rgb_im.save(fileName)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AfYWv5U-xNAU"
      },
      "source": [
        "My name is Kevin "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PjL0bY2TTYe3"
      },
      "source": [
        "## How to detect board positions:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CfROIrXDUxop"
      },
      "source": [
        "\n",
        "\n",
        "*   Total of 64 positions on the board, place one piece on each positions individually, generate data\n",
        "*   List item\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P8OQxCOU68wa"
      },
      "source": [
        "# Creating the Baseline Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QHYvg-bl7cvJ"
      },
      "source": [
        "Outline of Baseline Model:\n",
        "*   List item\n",
        "*   List item\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6HC58SXf7CHw"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_k3MzcaD7Cg5"
      },
      "source": [
        "# Our Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lapWqFms7iU1"
      },
      "source": [
        "- try overfitting using a small subsample of the dataset first (to see if we even have the capacity to do so)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hoQQqY7q7IbO"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gaqhzvay7Njb"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0R5--Qc27Mzt"
      },
      "source": [
        "# Summary of Results V1 (for Progress Report July 9th, 2021)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C86KgOGh7Yex"
      },
      "source": [
        "[insert summary here]"
      ]
    }
  ]
}